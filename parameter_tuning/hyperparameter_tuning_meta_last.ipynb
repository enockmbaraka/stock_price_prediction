{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac5af2-3057-4a98-9dcf-cd069e84415d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e2159ec-c606-4585-859b-a60cc9458eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\stock_price_prediction\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Dropout, MultiHeadAttention, LayerNormalization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, MultiHeadAttention, LayerNormalization\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1116f3d-6f0f-4e6a-a292-395eb2877172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data (e.g., exponential decay)\n",
    "def simulate_ode(k=0.1, y0=1.0, t_max=10, num_points=1000):\n",
    "    t = np.linspace(0, t_max, num_points)\n",
    "    y = y0 * np.exp(-k * t)\n",
    "    return t, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0b7581-3fbf-465d-9f37-129ceb8b0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_stock_data(csv_path, date_column='Date', close_column='Close', test_size=0.2, val_size=0.1, time_steps=60):\n",
    "    \"\"\"\n",
    "    Prepares stock market price data for time series modeling.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing the data.\n",
    "        date_column (str): Name of the date column in the CSV.\n",
    "        close_column (str): Name of the closing price column in the CSV.\n",
    "        test_size (float): Proportion of the data for testing.\n",
    "        val_size (float): Proportion of the training data for validation.\n",
    "        time_steps (int): Number of past time steps to use for each sample.\n",
    "    \n",
    "    Returns:\n",
    "        X_train, y_train: Training data and labels.\n",
    "        X_val, y_val: Validation data and labels.\n",
    "        X_test, y_test: Testing data and labels.\n",
    "        scaler: Fitted MinMaxScaler instance for inverse scaling.\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(csv_path, parse_dates=[date_column])\n",
    "    data.sort_values(by=date_column, inplace=True)\n",
    "    \n",
    "    # Extract the 'close' column for scaling\n",
    "    close_prices = data[close_column].values.reshape(-1, 1)\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_close = scaler.fit_transform(close_prices)\n",
    "    \n",
    "    # Create sequences of time_steps\n",
    "    X, y = [], []\n",
    "    for i in range(time_steps, len(scaled_close)):\n",
    "        X.append(scaled_close[i-time_steps:i])\n",
    "        y.append(scaled_close[i])\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    # Split data into train, validation, and test sets\n",
    "    train_size = int((1 - test_size) * len(X))\n",
    "    val_size = int(val_size * train_size)\n",
    "    \n",
    "    X_train, X_temp = X[:train_size], X[train_size:]\n",
    "    y_train, y_temp = y[:train_size], y[train_size:]\n",
    "    \n",
    "    X_val, X_test = X_temp[:val_size], X_temp[val_size:]\n",
    "    y_val, y_test = y_temp[:val_size], y_temp[val_size:]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c1f9f4-3cc9-4dc2-a799-eedcd3d4e38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (554, 60, 1), (554, 1)\n",
      "Validation shape: (55, 60, 1), (55, 1)\n",
      "Test shape: (84, 60, 1), (84, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the directory of the current script\n",
    "current_dir = os.getcwd()\n",
    "# Construct the path to the data folder (same level as the tuning folder)\n",
    "data_folder = os.path.join(current_dir, \"..\", \"inputs\")\n",
    "data_path_meta  = os.path.join(data_folder, \"meta_stock_cleaned.csv\")\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, scaler = preprocess_stock_data(\n",
    "    data_path_meta, date_column='Date', close_column='Close', time_steps=60\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e234d7-b087-416a-b0ad-2874c2d74198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def objective(trial, model_type):\n",
    "    # Common hyperparameters\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "\n",
    "    # Define the model based on the type\n",
    "    model = Sequential()\n",
    "    \n",
    "    if model_type == 'rnn':\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "        units = trial.suggest_int('units', 32, 256, step=32)\n",
    "        for _ in range(num_layers):\n",
    "            model.add(SimpleRNN(units, activation='tanh', return_sequences=True if _ < num_layers - 1 else False))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "    elif model_type == 'lstm':\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "        units = trial.suggest_int('units', 32, 256, step=32)\n",
    "        for _ in range(num_layers):\n",
    "            model.add(LSTM(units, activation='tanh', return_sequences=True if _ < num_layers - 1 else False))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "    elif model_type == 'transformer':\n",
    "        num_heads = trial.suggest_int('num_heads', 2, 8)\n",
    "        key_dim = trial.suggest_int('key_dim', 16, 64, step=16)\n",
    "        ff_units = trial.suggest_int('ff_units', 32, 128, step=32)\n",
    "    \n",
    "        # Input Layer\n",
    "        input_layer = tf.keras.layers.Input(shape=(None, 1))\n",
    "    \n",
    "        # Transformer Encoder Layer\n",
    "        attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(input_layer, input_layer)\n",
    "        attention_output = LayerNormalization()(attention_output)\n",
    "        attention_output = tf.keras.layers.Dense(ff_units, activation='relu')(attention_output)\n",
    "    \n",
    "         # Add a Dense layer for regression output\n",
    "        output_layer = tf.keras.layers.Dense(1)(attention_output)\n",
    "    \n",
    "         # Create a Model instead of Sequential\n",
    "        model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    elif model_type == 'neural_net':\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "        units = trial.suggest_int('units', 32, 256, step=32)\n",
    "        for _ in range(num_layers):\n",
    "            model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "    elif model_type == 'ode':\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "        units = trial.suggest_int('units', 32, 256, step=32)\n",
    "        activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid'])\n",
    "\n",
    "       # Input layer to handle sequences\n",
    "        input_layer = tf.keras.layers.Input(shape=(None, 1))\n",
    "    \n",
    "        # Stack Dense layers for feature extraction\n",
    "        x = input_layer\n",
    "        for _ in range(num_layers):\n",
    "            x = tf.keras.layers.Dense(units, activation=activation)(x)\n",
    "    \n",
    "        # Approximate the derivative using a Dense layer\n",
    "        derivative_layer = tf.keras.layers.Dense(units, activation=activation)(x)\n",
    "    \n",
    "        # Output layer for regression\n",
    "        output_layer = tf.keras.layers.Dense(1)(derivative_layer)\n",
    "    \n",
    "        # Define the functional model\n",
    "        model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Return the validation loss for Optuna to minimize\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    return val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcabb7-9914-4e5e-9e5b-f8d5f1fc0f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254dab6c-46bc-4441-b1bb-b6dfb6779d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a51f4ba-83ea-452e-8a24-e4f6c70ffde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 17:16:27,436] A new study created in memory with name: no-name-6bdc0c67-9ab3-45d1-9891-6f88ed6070f0\n",
      "C:\\Users\\Kuzey\\AppData\\Local\\Temp\\ipykernel_12028\\3026521219.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
      "[I 2024-12-18 17:16:41,241] Trial 0 finished with value: 0.0015435990644618869 and parameters: {'learning_rate': 0.0001818181327042405, 'batch_size': 128, 'num_layers': 3, 'units': 96}. Best is trial 0 with value: 0.0015435990644618869.\n",
      "[I 2024-12-18 17:16:47,408] Trial 1 finished with value: 0.06804265826940536 and parameters: {'learning_rate': 0.018698976087769065, 'batch_size': 16, 'num_layers': 1, 'units': 192}. Best is trial 0 with value: 0.0015435990644618869.\n",
      "[I 2024-12-18 17:16:54,347] Trial 2 finished with value: 0.0015601988416165113 and parameters: {'learning_rate': 0.0004193385682068946, 'batch_size': 64, 'num_layers': 3, 'units': 64}. Best is trial 0 with value: 0.0015435990644618869.\n",
      "[I 2024-12-18 17:17:06,580] Trial 3 finished with value: 0.18258985877037048 and parameters: {'learning_rate': 0.01731384505367868, 'batch_size': 32, 'num_layers': 3, 'units': 224}. Best is trial 0 with value: 0.0015435990644618869.\n",
      "[I 2024-12-18 17:17:13,382] Trial 4 finished with value: 0.0008305570227093995 and parameters: {'learning_rate': 0.001221564542887622, 'batch_size': 64, 'num_layers': 2, 'units': 160}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:17:24,079] Trial 5 finished with value: 0.23313115537166595 and parameters: {'learning_rate': 0.009860421543603589, 'batch_size': 16, 'num_layers': 3, 'units': 64}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:17:31,514] Trial 6 finished with value: 1.5180832147598267 and parameters: {'learning_rate': 0.014763466415090408, 'batch_size': 128, 'num_layers': 2, 'units': 224}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:17:40,389] Trial 7 finished with value: 0.14325369894504547 and parameters: {'learning_rate': 0.08422893869638017, 'batch_size': 64, 'num_layers': 3, 'units': 160}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:17:50,368] Trial 8 finished with value: 0.050817545503377914 and parameters: {'learning_rate': 0.0056945951562036926, 'batch_size': 32, 'num_layers': 3, 'units': 128}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:17:57,799] Trial 9 finished with value: 0.2023630291223526 and parameters: {'learning_rate': 0.0068061896842807985, 'batch_size': 32, 'num_layers': 2, 'units': 128}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:18:02,825] Trial 10 finished with value: 0.0015215394087135792 and parameters: {'learning_rate': 0.001296119742153721, 'batch_size': 64, 'num_layers': 1, 'units': 256}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:18:07,909] Trial 11 finished with value: 0.001170645235106349 and parameters: {'learning_rate': 0.0011722472488442824, 'batch_size': 64, 'num_layers': 1, 'units': 256}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:18:12,875] Trial 12 finished with value: 0.0010748014319688082 and parameters: {'learning_rate': 0.001270199195191192, 'batch_size': 64, 'num_layers': 1, 'units': 256}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:18:19,883] Trial 13 finished with value: 0.0009622450452297926 and parameters: {'learning_rate': 0.00146481200642227, 'batch_size': 64, 'num_layers': 2, 'units': 192}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:18:27,286] Trial 14 finished with value: 0.0013299478450790048 and parameters: {'learning_rate': 0.0004105703702755586, 'batch_size': 64, 'num_layers': 2, 'units': 160}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:18:34,819] Trial 15 finished with value: 0.15752121806144714 and parameters: {'learning_rate': 0.002567811633390755, 'batch_size': 64, 'num_layers': 2, 'units': 192}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:18:42,256] Trial 16 finished with value: 0.0011026308638975024 and parameters: {'learning_rate': 0.0005117104435253681, 'batch_size': 64, 'num_layers': 2, 'units': 192}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:18:50,977] Trial 17 finished with value: 0.004467213060706854 and parameters: {'learning_rate': 0.00011484180572195859, 'batch_size': 16, 'num_layers': 2, 'units': 32}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:18:57,848] Trial 18 finished with value: 0.46226876974105835 and parameters: {'learning_rate': 0.003078562457933282, 'batch_size': 128, 'num_layers': 2, 'units': 160}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:19:03,827] Trial 19 finished with value: 0.0012692356249317527 and parameters: {'learning_rate': 0.0008179750642292301, 'batch_size': 64, 'num_layers': 2, 'units': 96}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:19:08,680] Trial 20 finished with value: 0.13180400431156158 and parameters: {'learning_rate': 0.055158837382052454, 'batch_size': 64, 'num_layers': 1, 'units': 224}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:19:14,345] Trial 21 finished with value: 0.1599755883216858 and parameters: {'learning_rate': 0.0017470174272476062, 'batch_size': 64, 'num_layers': 1, 'units': 256}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:19:18,731] Trial 22 finished with value: 0.0025160443037748337 and parameters: {'learning_rate': 0.0008108401023839101, 'batch_size': 64, 'num_layers': 1, 'units': 192}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:19:26,811] Trial 23 finished with value: 0.002049788134172559 and parameters: {'learning_rate': 0.00024361330542417174, 'batch_size': 64, 'num_layers': 2, 'units': 224}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:19:30,570] Trial 24 finished with value: 0.001003239187411964 and parameters: {'learning_rate': 0.0021540527920630476, 'batch_size': 64, 'num_layers': 1, 'units': 128}. Best is trial 4 with value: 0.0008305570227093995.\n",
      "[I 2024-12-18 17:19:34,306] Trial 25 finished with value: 0.0008169717621058226 and parameters: {'learning_rate': 0.003610606100318876, 'batch_size': 64, 'num_layers': 1, 'units': 128}. Best is trial 25 with value: 0.0008169717621058226.\n",
      "[I 2024-12-18 17:19:39,441] Trial 26 finished with value: 0.7711449861526489 and parameters: {'learning_rate': 0.004287602433855246, 'batch_size': 128, 'num_layers': 2, 'units': 96}. Best is trial 25 with value: 0.0008169717621058226.\n",
      "[I 2024-12-18 17:19:48,691] Trial 27 finished with value: 0.038612641394138336 and parameters: {'learning_rate': 0.003763307940892737, 'batch_size': 16, 'num_layers': 2, 'units': 160}. Best is trial 25 with value: 0.0008169717621058226.\n",
      "[I 2024-12-18 17:19:52,997] Trial 28 finished with value: 0.13464617729187012 and parameters: {'learning_rate': 0.03515569030829128, 'batch_size': 32, 'num_layers': 1, 'units': 128}. Best is trial 25 with value: 0.0008169717621058226.\n",
      "[I 2024-12-18 17:19:59,874] Trial 29 finished with value: 0.0028082889039069414 and parameters: {'learning_rate': 0.000688230585690561, 'batch_size': 128, 'num_layers': 3, 'units': 96}. Best is trial 25 with value: 0.0008169717621058226.\n",
      "[I 2024-12-18 17:20:07,110] Trial 30 finished with value: 0.0015207920223474503 and parameters: {'learning_rate': 0.0002569244157709836, 'batch_size': 64, 'num_layers': 2, 'units': 160}. Best is trial 25 with value: 0.0008169717621058226.\n",
      "[I 2024-12-18 17:20:10,949] Trial 31 finished with value: 0.0010618474334478378 and parameters: {'learning_rate': 0.0024010735004710666, 'batch_size': 64, 'num_layers': 1, 'units': 128}. Best is trial 25 with value: 0.0008169717621058226.\n",
      "[I 2024-12-18 17:20:14,770] Trial 32 finished with value: 0.0012655239552259445 and parameters: {'learning_rate': 0.001991323539191865, 'batch_size': 64, 'num_layers': 1, 'units': 128}. Best is trial 25 with value: 0.0008169717621058226.\n",
      "[I 2024-12-18 17:20:18,204] Trial 33 finished with value: 0.0006927732028998435 and parameters: {'learning_rate': 0.00671956745653826, 'batch_size': 64, 'num_layers': 1, 'units': 64}. Best is trial 33 with value: 0.0006927732028998435.\n",
      "[I 2024-12-18 17:20:21,532] Trial 34 finished with value: 0.0005574619281105697 and parameters: {'learning_rate': 0.009437523455910169, 'batch_size': 64, 'num_layers': 1, 'units': 32}. Best is trial 34 with value: 0.0005574619281105697.\n",
      "[I 2024-12-18 17:20:26,283] Trial 35 finished with value: 0.0005762981018051505 and parameters: {'learning_rate': 0.010042087774440454, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 34 with value: 0.0005574619281105697.\n",
      "[I 2024-12-18 17:20:31,026] Trial 36 finished with value: 0.001266946317628026 and parameters: {'learning_rate': 0.010852158186886668, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 34 with value: 0.0005574619281105697.\n",
      "[I 2024-12-18 17:20:35,981] Trial 37 finished with value: 0.00042126147309318185 and parameters: {'learning_rate': 0.02662001088431487, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 37 with value: 0.00042126147309318185.\n",
      "[I 2024-12-18 17:20:41,008] Trial 38 finished with value: 0.001153202261775732 and parameters: {'learning_rate': 0.026791765119007514, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 37 with value: 0.00042126147309318185.\n",
      "[I 2024-12-18 17:20:46,136] Trial 39 finished with value: 0.0024475855752825737 and parameters: {'learning_rate': 0.02759075558072972, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 37 with value: 0.00042126147309318185.\n",
      "[I 2024-12-18 17:20:51,667] Trial 40 finished with value: 0.0010133846662938595 and parameters: {'learning_rate': 0.008170450074943198, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 37 with value: 0.00042126147309318185.\n",
      "[I 2024-12-18 17:20:56,468] Trial 41 finished with value: 0.0006295892526395619 and parameters: {'learning_rate': 0.012395324638104584, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 37 with value: 0.00042126147309318185.\n",
      "[I 2024-12-18 17:21:01,312] Trial 42 finished with value: 0.0007018636679276824 and parameters: {'learning_rate': 0.010816451437051084, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 37 with value: 0.00042126147309318185.\n",
      "[I 2024-12-18 17:21:06,290] Trial 43 finished with value: 0.0011393289314582944 and parameters: {'learning_rate': 0.015606940726725053, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 37 with value: 0.00042126147309318185.\n",
      "[I 2024-12-18 17:21:11,988] Trial 44 finished with value: 0.0005904422141611576 and parameters: {'learning_rate': 0.0057183724473756255, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 37 with value: 0.00042126147309318185.\n",
      "[I 2024-12-18 17:21:16,829] Trial 45 finished with value: 0.07882339507341385 and parameters: {'learning_rate': 0.023759726247572374, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 37 with value: 0.00042126147309318185.\n",
      "[I 2024-12-18 17:21:21,625] Trial 46 finished with value: 0.000385015009669587 and parameters: {'learning_rate': 0.04624064196479419, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:21:26,672] Trial 47 finished with value: 0.4315710663795471 and parameters: {'learning_rate': 0.09131992229930606, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:21:32,100] Trial 48 finished with value: 0.09828539937734604 and parameters: {'learning_rate': 0.044839742160884793, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:21:36,988] Trial 49 finished with value: 0.0010041926288977265 and parameters: {'learning_rate': 0.0684522007365141, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:21:41,078] Trial 50 finished with value: 0.004425451625138521 and parameters: {'learning_rate': 0.021305006979216903, 'batch_size': 32, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:21:46,089] Trial 51 finished with value: 0.0005625646444968879 and parameters: {'learning_rate': 0.01248041374145073, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:21:51,137] Trial 52 finished with value: 0.0006942322361283004 and parameters: {'learning_rate': 0.004844341857585277, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:21:56,343] Trial 53 finished with value: 0.0005621257587336004 and parameters: {'learning_rate': 0.008175400313855878, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:01,328] Trial 54 finished with value: 0.002132292138412595 and parameters: {'learning_rate': 0.040547657913323945, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:06,070] Trial 55 finished with value: 0.00048221377073787153 and parameters: {'learning_rate': 0.01726715285035, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:11,054] Trial 56 finished with value: 0.0004987859283573925 and parameters: {'learning_rate': 0.017377451877337108, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:16,340] Trial 57 finished with value: 0.24051274359226227 and parameters: {'learning_rate': 0.018734038135241004, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:20,410] Trial 58 finished with value: 0.1640244424343109 and parameters: {'learning_rate': 0.03293444068508179, 'batch_size': 32, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:23,570] Trial 59 finished with value: 0.14151014387607574 and parameters: {'learning_rate': 0.017846364423796807, 'batch_size': 128, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:28,915] Trial 60 finished with value: 0.016211049631237984 and parameters: {'learning_rate': 0.06312626454214997, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:34,599] Trial 61 finished with value: 0.0006937868893146515 and parameters: {'learning_rate': 0.013315306459982383, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:39,407] Trial 62 finished with value: 0.0007876655436120927 and parameters: {'learning_rate': 0.0074058144561281675, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:44,403] Trial 63 finished with value: 0.0011779482010751963 and parameters: {'learning_rate': 0.01582756980667995, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:49,361] Trial 64 finished with value: 0.0005456130020320415 and parameters: {'learning_rate': 0.008439525917267241, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:54,840] Trial 65 finished with value: 0.1480693519115448 and parameters: {'learning_rate': 0.049279910408087546, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:22:59,980] Trial 66 finished with value: 0.0013650070177391171 and parameters: {'learning_rate': 0.029181968646664513, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:03,272] Trial 67 finished with value: 0.0068418243899941444 and parameters: {'learning_rate': 0.00902361262325558, 'batch_size': 128, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:07,620] Trial 68 finished with value: 0.0004738859133794904 and parameters: {'learning_rate': 0.005469352926269097, 'batch_size': 32, 'num_layers': 1, 'units': 96}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:16,452] Trial 69 finished with value: 0.004387053661048412 and parameters: {'learning_rate': 0.004960865472360337, 'batch_size': 32, 'num_layers': 3, 'units': 96}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:20,458] Trial 70 finished with value: 0.175743967294693 and parameters: {'learning_rate': 0.022961335233484717, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:25,287] Trial 71 finished with value: 0.0008218318107537925 and parameters: {'learning_rate': 0.0058491950088492015, 'batch_size': 32, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:29,379] Trial 72 finished with value: 0.0007980259251780808 and parameters: {'learning_rate': 0.0029941715520417854, 'batch_size': 32, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:34,419] Trial 73 finished with value: 0.001708624535240233 and parameters: {'learning_rate': 0.008733651882826291, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:39,256] Trial 74 finished with value: 0.0013160627568140626 and parameters: {'learning_rate': 0.006783848317374534, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:43,445] Trial 75 finished with value: 0.0005658913287334144 and parameters: {'learning_rate': 0.037407392310235356, 'batch_size': 32, 'num_layers': 1, 'units': 96}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:48,635] Trial 76 finished with value: 0.0014547233004122972 and parameters: {'learning_rate': 0.012533263627933916, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:53,496] Trial 77 finished with value: 0.0006759329116903245 and parameters: {'learning_rate': 0.020774949598300837, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:23:56,641] Trial 78 finished with value: 1.9495893716812134 and parameters: {'learning_rate': 0.014543285050412427, 'batch_size': 128, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:01,650] Trial 79 finished with value: 0.0016820753226056695 and parameters: {'learning_rate': 0.003965674518625168, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:10,308] Trial 80 finished with value: 0.0007963433163240552 and parameters: {'learning_rate': 0.010510722594055022, 'batch_size': 16, 'num_layers': 2, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:15,164] Trial 81 finished with value: 0.0006413376540876925 and parameters: {'learning_rate': 0.012323857783760642, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:19,989] Trial 82 finished with value: 0.0007134643965400755 and parameters: {'learning_rate': 0.007224515326467944, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:24,727] Trial 83 finished with value: 0.0006875643157400191 and parameters: {'learning_rate': 0.01768317939382443, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:29,605] Trial 84 finished with value: 0.00046211006701923907 and parameters: {'learning_rate': 0.029966886298207252, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:34,650] Trial 85 finished with value: 0.015481279231607914 and parameters: {'learning_rate': 0.0320393195452284, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:37,941] Trial 86 finished with value: 0.003943340387195349 and parameters: {'learning_rate': 0.04470540673269029, 'batch_size': 64, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:43,312] Trial 87 finished with value: 0.02417878247797489 and parameters: {'learning_rate': 0.02545888631464752, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:47,642] Trial 88 finished with value: 0.0004628984024748206 and parameters: {'learning_rate': 0.07556100160835132, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:52,267] Trial 89 finished with value: 0.0048200408928096294 and parameters: {'learning_rate': 0.07930755927453599, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:24:56,448] Trial 90 finished with value: 0.03853798285126686 and parameters: {'learning_rate': 0.09987242388961856, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:25:00,581] Trial 91 finished with value: 0.27782848477363586 and parameters: {'learning_rate': 0.05422046041345202, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:25:04,439] Trial 92 finished with value: 0.0008062015986070037 and parameters: {'learning_rate': 0.0681533680007556, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:25:10,016] Trial 93 finished with value: 0.0017523779533803463 and parameters: {'learning_rate': 0.03930322480844785, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:25:14,168] Trial 94 finished with value: 0.0015410904306918383 and parameters: {'learning_rate': 0.020076924794703584, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:25:17,863] Trial 95 finished with value: 0.0006676416378468275 and parameters: {'learning_rate': 0.07943140243999212, 'batch_size': 64, 'num_layers': 1, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:25:23,464] Trial 96 finished with value: 0.00043381008435972035 and parameters: {'learning_rate': 0.030801417787837328, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:25:34,199] Trial 97 finished with value: 0.203582763671875 and parameters: {'learning_rate': 0.03120407091708822, 'batch_size': 16, 'num_layers': 3, 'units': 32}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:25:39,495] Trial 98 finished with value: 0.23953184485435486 and parameters: {'learning_rate': 0.06113950366940367, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 46 with value: 0.000385015009669587.\n",
      "[I 2024-12-18 17:25:42,689] Trial 99 finished with value: 0.09285212308168411 and parameters: {'learning_rate': 0.02689201839907293, 'batch_size': 128, 'num_layers': 1, 'units': 64}. Best is trial 46 with value: 0.000385015009669587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RNN parameters: {'learning_rate': 0.04624064196479419, 'batch_size': 16, 'num_layers': 1, 'units': 32}\n"
     ]
    }
   ],
   "source": [
    "study_rnn = optuna.create_study(direction='minimize')\n",
    "study_rnn.optimize(lambda trial: objective(trial, model_type='rnn'), n_trials=100)\n",
    "print(\"Best RNN parameters:\", study_rnn.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f268f-4a2d-478f-9e29-e3dbcc1edd67",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3e42b9c-c300-46f5-b779-fd7d788ffc50",
   "metadata": {},
   "source": [
    "Best is trial 46 with value: 0.000385015009669587. Best RNN parameters: {'learning_rate': 0.04624064196479419, 'batch_size': 16, 'num_layers': 1, 'units': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c414e9-1095-4806-b643-b343b0c5f87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b98fe6-68d0-434a-ac11-0f38df1107e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecdd1561-051c-4092-bddd-096485f27162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 17:25:42,700] A new study created in memory with name: no-name-16c663a8-304d-4ff3-a472-76bee13971bb\n",
      "C:\\Users\\Kuzey\\AppData\\Local\\Temp\\ipykernel_12028\\3026521219.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
      "[I 2024-12-18 17:26:11,373] Trial 0 finished with value: 0.0014686486683785915 and parameters: {'learning_rate': 0.0008991938863668174, 'batch_size': 32, 'num_layers': 2, 'units': 256}. Best is trial 0 with value: 0.0014686486683785915.\n",
      "[I 2024-12-18 17:26:29,431] Trial 1 finished with value: 0.002384783932939172 and parameters: {'learning_rate': 0.00047229595529527216, 'batch_size': 16, 'num_layers': 2, 'units': 96}. Best is trial 0 with value: 0.0014686486683785915.\n",
      "[I 2024-12-18 17:26:44,338] Trial 2 finished with value: 0.00660803122445941 and parameters: {'learning_rate': 0.00030219011398303664, 'batch_size': 32, 'num_layers': 3, 'units': 64}. Best is trial 0 with value: 0.0014686486683785915.\n",
      "[I 2024-12-18 17:26:50,776] Trial 3 finished with value: 0.21020321547985077 and parameters: {'learning_rate': 0.01966884287316429, 'batch_size': 64, 'num_layers': 1, 'units': 128}. Best is trial 0 with value: 0.0014686486683785915.\n",
      "[I 2024-12-18 17:27:05,492] Trial 4 finished with value: 0.0023526467848569155 and parameters: {'learning_rate': 0.00038645500662622367, 'batch_size': 32, 'num_layers': 2, 'units': 128}. Best is trial 0 with value: 0.0014686486683785915.\n",
      "[I 2024-12-18 17:27:19,977] Trial 5 finished with value: 0.0025804825127124786 and parameters: {'learning_rate': 0.0008638058388274753, 'batch_size': 64, 'num_layers': 2, 'units': 192}. Best is trial 0 with value: 0.0014686486683785915.\n",
      "[I 2024-12-18 17:27:54,569] Trial 6 finished with value: 0.003063989570364356 and parameters: {'learning_rate': 0.0005334813777509771, 'batch_size': 32, 'num_layers': 3, 'units': 224}. Best is trial 0 with value: 0.0014686486683785915.\n",
      "[I 2024-12-18 17:27:59,990] Trial 7 finished with value: 0.001439763349480927 and parameters: {'learning_rate': 0.01223868251294618, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 7 with value: 0.001439763349480927.\n",
      "[I 2024-12-18 17:28:11,799] Trial 8 finished with value: 0.003766340669244528 and parameters: {'learning_rate': 0.0024020551435017003, 'batch_size': 128, 'num_layers': 2, 'units': 160}. Best is trial 7 with value: 0.001439763349480927.\n",
      "[I 2024-12-18 17:28:21,342] Trial 9 finished with value: 0.5701134204864502 and parameters: {'learning_rate': 0.08907343824611312, 'batch_size': 32, 'num_layers': 1, 'units': 192}. Best is trial 7 with value: 0.001439763349480927.\n",
      "[I 2024-12-18 17:28:25,241] Trial 10 finished with value: 0.0011491936165839434 and parameters: {'learning_rate': 0.007215084889518255, 'batch_size': 128, 'num_layers': 1, 'units': 32}. Best is trial 10 with value: 0.0011491936165839434.\n",
      "[I 2024-12-18 17:28:29,160] Trial 11 finished with value: 0.001026163692586124 and parameters: {'learning_rate': 0.010685267445820225, 'batch_size': 128, 'num_layers': 1, 'units': 32}. Best is trial 11 with value: 0.001026163692586124.\n",
      "[I 2024-12-18 17:28:33,060] Trial 12 finished with value: 0.0011874717893078923 and parameters: {'learning_rate': 0.008861654034241847, 'batch_size': 128, 'num_layers': 1, 'units': 32}. Best is trial 11 with value: 0.001026163692586124.\n",
      "[I 2024-12-18 17:28:37,423] Trial 13 finished with value: 0.0013115996262058616 and parameters: {'learning_rate': 0.004003149944022518, 'batch_size': 128, 'num_layers': 1, 'units': 64}. Best is trial 11 with value: 0.001026163692586124.\n",
      "[I 2024-12-18 17:28:41,813] Trial 14 finished with value: 0.12528790533542633 and parameters: {'learning_rate': 0.06407990385781215, 'batch_size': 128, 'num_layers': 1, 'units': 64}. Best is trial 11 with value: 0.001026163692586124.\n",
      "[I 2024-12-18 17:28:45,755] Trial 15 finished with value: 0.0007243998115882277 and parameters: {'learning_rate': 0.03244623108461094, 'batch_size': 128, 'num_layers': 1, 'units': 32}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:28:55,141] Trial 16 finished with value: 0.00088694499572739 and parameters: {'learning_rate': 0.03571379063261424, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:29:04,924] Trial 17 finished with value: 0.0039050080813467503 and parameters: {'learning_rate': 0.034492046726511245, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:29:27,633] Trial 18 finished with value: 0.17277106642723083 and parameters: {'learning_rate': 0.03332337975909691, 'batch_size': 16, 'num_layers': 3, 'units': 96}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:29:43,994] Trial 19 finished with value: 0.0030140671879053116 and parameters: {'learning_rate': 0.00014261399503334019, 'batch_size': 16, 'num_layers': 2, 'units': 64}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:30:07,363] Trial 20 finished with value: 0.010970049537718296 and parameters: {'learning_rate': 0.04367878669869043, 'batch_size': 16, 'num_layers': 2, 'units': 160}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:30:11,506] Trial 21 finished with value: 0.0008195207337848842 and parameters: {'learning_rate': 0.018457862804853623, 'batch_size': 128, 'num_layers': 1, 'units': 32}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:30:16,589] Trial 22 finished with value: 0.12892788648605347 and parameters: {'learning_rate': 0.021780671081902587, 'batch_size': 128, 'num_layers': 1, 'units': 96}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:30:21,023] Trial 23 finished with value: 0.13096196949481964 and parameters: {'learning_rate': 0.09735633408775936, 'batch_size': 128, 'num_layers': 1, 'units': 64}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:30:25,467] Trial 24 finished with value: 0.0027316100895404816 and parameters: {'learning_rate': 0.003496746491050143, 'batch_size': 64, 'num_layers': 1, 'units': 32}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:30:36,811] Trial 25 finished with value: 0.29445576667785645 and parameters: {'learning_rate': 0.019177923379086897, 'batch_size': 16, 'num_layers': 1, 'units': 128}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:30:41,219] Trial 26 finished with value: 0.11870300769805908 and parameters: {'learning_rate': 0.04985480389912512, 'batch_size': 128, 'num_layers': 1, 'units': 64}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:30:45,164] Trial 27 finished with value: 0.0012589461402967572 and parameters: {'learning_rate': 0.006238642430547857, 'batch_size': 128, 'num_layers': 1, 'units': 32}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:31:01,624] Trial 28 finished with value: 0.001400199718773365 and parameters: {'learning_rate': 0.0019796611853910725, 'batch_size': 16, 'num_layers': 2, 'units': 96}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:31:23,039] Trial 29 finished with value: 0.2930834889411926 and parameters: {'learning_rate': 0.019867862496913285, 'batch_size': 64, 'num_layers': 2, 'units': 256}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:31:27,489] Trial 30 finished with value: 0.0012753818882629275 and parameters: {'learning_rate': 0.028691874340256142, 'batch_size': 128, 'num_layers': 1, 'units': 64}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:31:31,539] Trial 31 finished with value: 0.0014340025372803211 and parameters: {'learning_rate': 0.012208109152942008, 'batch_size': 128, 'num_layers': 1, 'units': 32}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:31:35,541] Trial 32 finished with value: 0.001043414231389761 and parameters: {'learning_rate': 0.01047022844203872, 'batch_size': 128, 'num_layers': 1, 'units': 32}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:31:39,455] Trial 33 finished with value: 0.0017830936703830957 and parameters: {'learning_rate': 0.06417658263028321, 'batch_size': 128, 'num_layers': 1, 'units': 32}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:31:47,454] Trial 34 finished with value: 0.0022402945905923843 and parameters: {'learning_rate': 0.005413427678173198, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:31:52,465] Trial 35 finished with value: 0.0014711313415318727 and parameters: {'learning_rate': 0.01400691961306142, 'batch_size': 128, 'num_layers': 1, 'units': 96}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:31:59,996] Trial 36 finished with value: 0.0033639634493738413 and parameters: {'learning_rate': 0.02525905781572535, 'batch_size': 128, 'num_layers': 2, 'units': 64}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:32:17,823] Trial 37 finished with value: 0.009347043931484222 and parameters: {'learning_rate': 0.01510313584353266, 'batch_size': 64, 'num_layers': 3, 'units': 128}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:32:24,094] Trial 38 finished with value: 0.0009120861068367958 and parameters: {'learning_rate': 0.04359718771790992, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:32:36,287] Trial 39 finished with value: 0.4336310625076294 and parameters: {'learning_rate': 0.049094273948574664, 'batch_size': 32, 'num_layers': 2, 'units': 96}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:32:46,636] Trial 40 finished with value: 0.029525110498070717 and parameters: {'learning_rate': 0.07135004617898756, 'batch_size': 32, 'num_layers': 1, 'units': 224}. Best is trial 15 with value: 0.0007243998115882277.\n",
      "[I 2024-12-18 17:32:52,083] Trial 41 finished with value: 0.0006069032824598253 and parameters: {'learning_rate': 0.038004600852379805, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:32:57,869] Trial 42 finished with value: 0.0012052699457854033 and parameters: {'learning_rate': 0.041459965104768355, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:33:05,649] Trial 43 finished with value: 0.0012402388965710998 and parameters: {'learning_rate': 0.03080523727725758, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:33:12,138] Trial 44 finished with value: 0.012801230885088444 and parameters: {'learning_rate': 0.06997823599886162, 'batch_size': 32, 'num_layers': 1, 'units': 64}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:33:17,897] Trial 45 finished with value: 0.0023649006616324186 and parameters: {'learning_rate': 0.001131946709939943, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:33:23,751] Trial 46 finished with value: 0.0008111248025670648 and parameters: {'learning_rate': 0.017666137692733102, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:33:41,601] Trial 47 finished with value: 0.23448137938976288 and parameters: {'learning_rate': 0.01576418723203534, 'batch_size': 32, 'num_layers': 2, 'units': 160}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:33:48,480] Trial 48 finished with value: 0.0009612399153411388 and parameters: {'learning_rate': 0.008227566737992544, 'batch_size': 32, 'num_layers': 1, 'units': 64}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:33:56,227] Trial 49 finished with value: 0.0006627027178183198 and parameters: {'learning_rate': 0.027902147312255963, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:34:01,759] Trial 50 finished with value: 0.0011913098860532045 and parameters: {'learning_rate': 0.004795424217650731, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:34:09,122] Trial 51 finished with value: 0.0007624579011462629 and parameters: {'learning_rate': 0.025213999441560983, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:34:16,705] Trial 52 finished with value: 0.0006304467096924782 and parameters: {'learning_rate': 0.02194732549937987, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:34:24,130] Trial 53 finished with value: 0.0007853147108107805 and parameters: {'learning_rate': 0.026413701696222033, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 41 with value: 0.0006069032824598253.\n",
      "[I 2024-12-18 17:34:32,511] Trial 54 finished with value: 0.0005484013818204403 and parameters: {'learning_rate': 0.025924052111893955, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 54 with value: 0.0005484013818204403.\n",
      "[I 2024-12-18 17:34:41,019] Trial 55 finished with value: 0.0013128028949722648 and parameters: {'learning_rate': 0.05578214996106173, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 54 with value: 0.0005484013818204403.\n",
      "[I 2024-12-18 17:34:49,066] Trial 56 finished with value: 0.0005110646015964448 and parameters: {'learning_rate': 0.026527307178332682, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 56 with value: 0.0005110646015964448.\n",
      "[I 2024-12-18 17:34:57,134] Trial 57 finished with value: 0.12161610275506973 and parameters: {'learning_rate': 0.08019105163338572, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 56 with value: 0.0005110646015964448.\n",
      "[I 2024-12-18 17:35:05,113] Trial 58 finished with value: 0.0004047076217830181 and parameters: {'learning_rate': 0.03771761232679323, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:35:13,187] Trial 59 finished with value: 0.000534146442078054 and parameters: {'learning_rate': 0.03783395946748358, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:35:27,847] Trial 60 finished with value: 0.1420164555311203 and parameters: {'learning_rate': 0.09817498917961771, 'batch_size': 16, 'num_layers': 2, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:35:35,844] Trial 61 finished with value: 0.0005055939545854926 and parameters: {'learning_rate': 0.03679323110252246, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:35:44,892] Trial 62 finished with value: 0.0008661879110150039 and parameters: {'learning_rate': 0.038909400990005914, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:35:52,830] Trial 63 finished with value: 0.0005903747514821589 and parameters: {'learning_rate': 0.056310248646392363, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:36:01,904] Trial 64 finished with value: 0.039111144840717316 and parameters: {'learning_rate': 0.05106209414928304, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:36:10,149] Trial 65 finished with value: 0.011361110024154186 and parameters: {'learning_rate': 0.03655683682455653, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:36:18,180] Trial 66 finished with value: 0.00440404936671257 and parameters: {'learning_rate': 0.06102177478794567, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:36:27,634] Trial 67 finished with value: 0.0030998587608337402 and parameters: {'learning_rate': 0.00027261844858293325, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:36:35,742] Trial 68 finished with value: 0.002183053642511368 and parameters: {'learning_rate': 0.03310755232439351, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:36:45,220] Trial 69 finished with value: 0.0017019014339894056 and parameters: {'learning_rate': 0.07906303609479307, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:36:58,348] Trial 70 finished with value: 0.004336220677942038 and parameters: {'learning_rate': 0.05387704737737966, 'batch_size': 16, 'num_layers': 1, 'units': 192}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:37:06,434] Trial 71 finished with value: 0.000887481844983995 and parameters: {'learning_rate': 0.021991312043665133, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:37:27,212] Trial 72 finished with value: 0.0034080976620316505 and parameters: {'learning_rate': 0.02179991821783199, 'batch_size': 16, 'num_layers': 3, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:37:35,698] Trial 73 finished with value: 0.0030706822872161865 and parameters: {'learning_rate': 0.04498570775912593, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:37:47,805] Trial 74 finished with value: 0.0006429064669646323 and parameters: {'learning_rate': 0.011062806961000603, 'batch_size': 16, 'num_layers': 1, 'units': 128}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:37:55,137] Trial 75 finished with value: 0.0009711872553452849 and parameters: {'learning_rate': 0.03596822105360224, 'batch_size': 64, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:38:03,576] Trial 76 finished with value: 0.000589913921430707 and parameters: {'learning_rate': 0.013516957755077885, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:38:11,766] Trial 77 finished with value: 0.0010536861373111606 and parameters: {'learning_rate': 0.002721059867257965, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:38:20,977] Trial 78 finished with value: 0.0012004692107439041 and parameters: {'learning_rate': 0.016041741684498775, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:38:29,139] Trial 79 finished with value: 0.0017090917099267244 and parameters: {'learning_rate': 0.01346220427904608, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:38:38,267] Trial 80 finished with value: 0.17614609003067017 and parameters: {'learning_rate': 0.028290927664561146, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:38:46,828] Trial 81 finished with value: 0.0013956421753391623 and parameters: {'learning_rate': 0.0228500878499858, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:38:54,178] Trial 82 finished with value: 0.0005408277502283454 and parameters: {'learning_rate': 0.04403528452444863, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:39:02,245] Trial 83 finished with value: 0.0006792197818867862 and parameters: {'learning_rate': 0.04218225685540698, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:39:06,827] Trial 84 finished with value: 0.0015740912640467286 and parameters: {'learning_rate': 0.06349735341692372, 'batch_size': 64, 'num_layers': 1, 'units': 32}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:39:14,363] Trial 85 finished with value: 0.0007810341194272041 and parameters: {'learning_rate': 0.032492434054159594, 'batch_size': 16, 'num_layers': 1, 'units': 32}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:39:22,497] Trial 86 finished with value: 0.0045637283474206924 and parameters: {'learning_rate': 0.08379239247813583, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:39:31,604] Trial 87 finished with value: 0.0004865248629357666 and parameters: {'learning_rate': 0.048673715236096295, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:39:40,641] Trial 88 finished with value: 0.5041409134864807 and parameters: {'learning_rate': 0.048794149251489144, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:39:49,735] Trial 89 finished with value: 0.0016422803746536374 and parameters: {'learning_rate': 0.05773030863472571, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:39:57,856] Trial 90 finished with value: 0.0006043342291377485 and parameters: {'learning_rate': 0.01799244040793034, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:40:05,780] Trial 91 finished with value: 0.0033389132004231215 and parameters: {'learning_rate': 0.030103416378897633, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:40:14,060] Trial 92 finished with value: 0.0008995815296657383 and parameters: {'learning_rate': 0.01784293762017306, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:40:22,065] Trial 93 finished with value: 0.0010354620171710849 and parameters: {'learning_rate': 0.02505564933004104, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:40:31,166] Trial 94 finished with value: 0.0007779820589348674 and parameters: {'learning_rate': 0.008747142556980649, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:40:39,245] Trial 95 finished with value: 0.0014429360162466764 and parameters: {'learning_rate': 0.04138404505462222, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:40:50,636] Trial 96 finished with value: 0.2692205011844635 and parameters: {'learning_rate': 0.06940419419099131, 'batch_size': 16, 'num_layers': 1, 'units': 128}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:40:58,776] Trial 97 finished with value: 0.0006361934938468039 and parameters: {'learning_rate': 0.04709064068029198, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:41:07,055] Trial 98 finished with value: 0.0004771118110511452 and parameters: {'learning_rate': 0.01865798334371068, 'batch_size': 16, 'num_layers': 1, 'units': 64}. Best is trial 58 with value: 0.0004047076217830181.\n",
      "[I 2024-12-18 17:41:16,195] Trial 99 finished with value: 0.0012763978447765112 and parameters: {'learning_rate': 0.036069465635199284, 'batch_size': 16, 'num_layers': 1, 'units': 96}. Best is trial 58 with value: 0.0004047076217830181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LSTM parameters: {'learning_rate': 0.03771761232679323, 'batch_size': 16, 'num_layers': 1, 'units': 64}\n"
     ]
    }
   ],
   "source": [
    "study_lstm = optuna.create_study(direction='minimize')\n",
    "study_lstm.optimize(lambda trial: objective(trial, model_type='lstm'), n_trials=100)\n",
    "print(\"Best LSTM parameters:\", study_lstm.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a6d6e8-c03b-4903-ac43-69d586758228",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b267d94-91bd-4c34-8a82-a5aee65c7c88",
   "metadata": {},
   "source": [
    "Best is trial 58 with value: 0.0004047076217830181. Best LSTM parameters: {'learning_rate': 0.03771761232679323, 'batch_size': 16, 'num_layers': 1, 'units': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a63724a-4988-4b36-8ab7-996a158ebc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 17:41:16,204] A new study created in memory with name: no-name-edf572f4-0219-4b35-85c1-64295ad576a0\n",
      "C:\\Users\\Kuzey\\AppData\\Local\\Temp\\ipykernel_12028\\3026521219.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
      "[I 2024-12-18 17:41:21,873] Trial 0 finished with value: 0.2129543423652649 and parameters: {'learning_rate': 0.007323015671634435, 'batch_size': 64, 'num_heads': 2, 'key_dim': 48, 'ff_units': 32}. Best is trial 0 with value: 0.2129543423652649.\n",
      "[I 2024-12-18 17:41:28,085] Trial 1 finished with value: 0.589206337928772 and parameters: {'learning_rate': 0.00018345832886461382, 'batch_size': 128, 'num_heads': 5, 'key_dim': 48, 'ff_units': 32}. Best is trial 0 with value: 0.2129543423652649.\n",
      "[I 2024-12-18 17:41:35,189] Trial 2 finished with value: 0.21174371242523193 and parameters: {'learning_rate': 0.016419552493569693, 'batch_size': 64, 'num_heads': 8, 'key_dim': 32, 'ff_units': 32}. Best is trial 2 with value: 0.21174371242523193.\n",
      "[I 2024-12-18 17:41:43,263] Trial 3 finished with value: 0.5721621513366699 and parameters: {'learning_rate': 0.00011559302157910264, 'batch_size': 32, 'num_heads': 6, 'key_dim': 64, 'ff_units': 32}. Best is trial 2 with value: 0.21174371242523193.\n",
      "[I 2024-12-18 17:41:49,004] Trial 4 finished with value: 0.21188703179359436 and parameters: {'learning_rate': 0.00831035961328954, 'batch_size': 64, 'num_heads': 4, 'key_dim': 48, 'ff_units': 32}. Best is trial 2 with value: 0.21174371242523193.\n",
      "[I 2024-12-18 17:41:57,329] Trial 5 finished with value: 0.33147451281547546 and parameters: {'learning_rate': 0.0007377638081589496, 'batch_size': 16, 'num_heads': 6, 'key_dim': 64, 'ff_units': 128}. Best is trial 2 with value: 0.21174371242523193.\n",
      "[I 2024-12-18 17:42:04,858] Trial 6 finished with value: 0.24106183648109436 and parameters: {'learning_rate': 0.06069640763155772, 'batch_size': 128, 'num_heads': 7, 'key_dim': 48, 'ff_units': 32}. Best is trial 2 with value: 0.21174371242523193.\n",
      "[I 2024-12-18 17:42:11,784] Trial 7 finished with value: 0.48082560300827026 and parameters: {'learning_rate': 0.0009775727226676877, 'batch_size': 64, 'num_heads': 8, 'key_dim': 32, 'ff_units': 128}. Best is trial 2 with value: 0.21174371242523193.\n",
      "[I 2024-12-18 17:42:17,090] Trial 8 finished with value: 0.1917893886566162 and parameters: {'learning_rate': 0.07579019066336533, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 8 with value: 0.1917893886566162.\n",
      "[I 2024-12-18 17:42:22,747] Trial 9 finished with value: 0.28807953000068665 and parameters: {'learning_rate': 0.0034120416807896523, 'batch_size': 64, 'num_heads': 5, 'key_dim': 16, 'ff_units': 128}. Best is trial 8 with value: 0.1917893886566162.\n",
      "[I 2024-12-18 17:42:28,936] Trial 10 finished with value: 0.16900095343589783 and parameters: {'learning_rate': 0.09811883327290226, 'batch_size': 16, 'num_heads': 2, 'key_dim': 16, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:42:34,808] Trial 11 finished with value: 0.23526541888713837 and parameters: {'learning_rate': 0.09988412290380118, 'batch_size': 16, 'num_heads': 2, 'key_dim': 16, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:42:40,724] Trial 12 finished with value: 0.2101254165172577 and parameters: {'learning_rate': 0.033800499397583554, 'batch_size': 16, 'num_heads': 3, 'key_dim': 16, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:42:46,870] Trial 13 finished with value: 0.2003086805343628 and parameters: {'learning_rate': 0.02947130914007997, 'batch_size': 16, 'num_heads': 3, 'key_dim': 32, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:42:55,759] Trial 14 finished with value: 0.21703878045082092 and parameters: {'learning_rate': 0.08728768728219329, 'batch_size': 16, 'num_heads': 3, 'key_dim': 16, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:43:01,088] Trial 15 finished with value: 0.21105535328388214 and parameters: {'learning_rate': 0.01696230931572743, 'batch_size': 32, 'num_heads': 2, 'key_dim': 32, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:43:07,300] Trial 16 finished with value: 0.18851883709430695 and parameters: {'learning_rate': 0.038126550417206466, 'batch_size': 16, 'num_heads': 4, 'key_dim': 16, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:43:13,484] Trial 17 finished with value: 0.20873190462589264 and parameters: {'learning_rate': 0.039282139444134556, 'batch_size': 16, 'num_heads': 4, 'key_dim': 16, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:43:19,474] Trial 18 finished with value: 0.22037705779075623 and parameters: {'learning_rate': 0.0019630974480921003, 'batch_size': 16, 'num_heads': 4, 'key_dim': 16, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:43:25,067] Trial 19 finished with value: 0.20947693288326263 and parameters: {'learning_rate': 0.010596169205361447, 'batch_size': 32, 'num_heads': 3, 'key_dim': 16, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:43:30,562] Trial 20 finished with value: 0.35078316926956177 and parameters: {'learning_rate': 0.004149795055580614, 'batch_size': 128, 'num_heads': 4, 'key_dim': 32, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:43:36,505] Trial 21 finished with value: 0.24636028707027435 and parameters: {'learning_rate': 0.04928089598722599, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:43:42,404] Trial 22 finished with value: 0.20627105236053467 and parameters: {'learning_rate': 0.027704206180325645, 'batch_size': 16, 'num_heads': 3, 'key_dim': 16, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:43:48,259] Trial 23 finished with value: 0.20132362842559814 and parameters: {'learning_rate': 0.06849446429267907, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:43:54,251] Trial 24 finished with value: 0.23782868683338165 and parameters: {'learning_rate': 0.018533833795756818, 'batch_size': 16, 'num_heads': 3, 'key_dim': 16, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:44:01,714] Trial 25 finished with value: 0.2367839515209198 and parameters: {'learning_rate': 0.09409175737396898, 'batch_size': 16, 'num_heads': 5, 'key_dim': 32, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:44:07,957] Trial 26 finished with value: 0.23895905911922455 and parameters: {'learning_rate': 0.046119443765225455, 'batch_size': 16, 'num_heads': 6, 'key_dim': 16, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:44:13,687] Trial 27 finished with value: 0.20948339998722076 and parameters: {'learning_rate': 0.024027198738038488, 'batch_size': 16, 'num_heads': 2, 'key_dim': 16, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:44:19,380] Trial 28 finished with value: 0.21623095870018005 and parameters: {'learning_rate': 0.012299758285047532, 'batch_size': 32, 'num_heads': 4, 'key_dim': 32, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:44:24,588] Trial 29 finished with value: 0.31099480390548706 and parameters: {'learning_rate': 0.005065406347116721, 'batch_size': 128, 'num_heads': 2, 'key_dim': 48, 'ff_units': 128}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:44:30,264] Trial 30 finished with value: 0.23408694565296173 and parameters: {'learning_rate': 0.05897139179868305, 'batch_size': 16, 'num_heads': 3, 'key_dim': 16, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:44:36,736] Trial 31 finished with value: 0.24085022509098053 and parameters: {'learning_rate': 0.029678666438923407, 'batch_size': 16, 'num_heads': 3, 'key_dim': 32, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:44:42,890] Trial 32 finished with value: 0.18959581851959229 and parameters: {'learning_rate': 0.047332211311870175, 'batch_size': 16, 'num_heads': 2, 'key_dim': 48, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:44:49,195] Trial 33 finished with value: 0.2166881114244461 and parameters: {'learning_rate': 0.0507461932340007, 'batch_size': 16, 'num_heads': 2, 'key_dim': 48, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:44:55,752] Trial 34 finished with value: 0.3987969756126404 and parameters: {'learning_rate': 0.0004832476888466078, 'batch_size': 16, 'num_heads': 2, 'key_dim': 64, 'ff_units': 32}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:45:01,126] Trial 35 finished with value: 0.22476281225681305 and parameters: {'learning_rate': 0.07025652541408768, 'batch_size': 128, 'num_heads': 2, 'key_dim': 48, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:45:10,586] Trial 36 finished with value: 0.21474650502204895 and parameters: {'learning_rate': 0.01965973670968602, 'batch_size': 64, 'num_heads': 7, 'key_dim': 64, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:45:17,109] Trial 37 finished with value: 0.22162465751171112 and parameters: {'learning_rate': 0.00196583648092783, 'batch_size': 16, 'num_heads': 4, 'key_dim': 48, 'ff_units': 32}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:45:23,647] Trial 38 finished with value: 0.2164572924375534 and parameters: {'learning_rate': 0.007263624312170226, 'batch_size': 32, 'num_heads': 5, 'key_dim': 48, 'ff_units': 128}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:45:29,590] Trial 39 finished with value: 0.2148166298866272 and parameters: {'learning_rate': 0.03909229766805971, 'batch_size': 64, 'num_heads': 3, 'key_dim': 64, 'ff_units': 32}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:45:37,003] Trial 40 finished with value: 0.43598487973213196 and parameters: {'learning_rate': 0.00037231278922866964, 'batch_size': 16, 'num_heads': 7, 'key_dim': 32, 'ff_units': 128}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:45:42,933] Trial 41 finished with value: 0.19577333331108093 and parameters: {'learning_rate': 0.07890055880098729, 'batch_size': 16, 'num_heads': 3, 'key_dim': 32, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:45:48,967] Trial 42 finished with value: 0.24329979717731476 and parameters: {'learning_rate': 0.07228987688613701, 'batch_size': 16, 'num_heads': 2, 'key_dim': 48, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:45:55,064] Trial 43 finished with value: 0.17658637464046478 and parameters: {'learning_rate': 0.057583925383489984, 'batch_size': 16, 'num_heads': 3, 'key_dim': 32, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:46:01,669] Trial 44 finished with value: 0.2704017758369446 and parameters: {'learning_rate': 0.052077822025668165, 'batch_size': 16, 'num_heads': 4, 'key_dim': 48, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:46:07,284] Trial 45 finished with value: 0.21323660016059875 and parameters: {'learning_rate': 0.09670601131868152, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:46:12,059] Trial 46 finished with value: 0.21819673478603363 and parameters: {'learning_rate': 0.03484486965335216, 'batch_size': 64, 'num_heads': 3, 'key_dim': 16, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:46:16,533] Trial 47 finished with value: 0.2271878868341446 and parameters: {'learning_rate': 0.021198853568687386, 'batch_size': 128, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:46:22,699] Trial 48 finished with value: 0.22636964917182922 and parameters: {'learning_rate': 0.01365444948235361, 'batch_size': 16, 'num_heads': 3, 'key_dim': 48, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:46:28,589] Trial 49 finished with value: 0.5492005348205566 and parameters: {'learning_rate': 0.0001061926659189697, 'batch_size': 16, 'num_heads': 4, 'key_dim': 16, 'ff_units': 128}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:46:33,402] Trial 50 finished with value: 0.21739889681339264 and parameters: {'learning_rate': 0.04007125163473618, 'batch_size': 32, 'num_heads': 2, 'key_dim': 16, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:46:39,422] Trial 51 finished with value: 0.22944113612174988 and parameters: {'learning_rate': 0.07436667524018262, 'batch_size': 16, 'num_heads': 3, 'key_dim': 32, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:46:45,311] Trial 52 finished with value: 0.2443433552980423 and parameters: {'learning_rate': 0.06258259120582083, 'batch_size': 16, 'num_heads': 3, 'key_dim': 32, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:46:50,907] Trial 53 finished with value: 0.18692637979984283 and parameters: {'learning_rate': 0.0960686420515856, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:46:56,288] Trial 54 finished with value: 0.23851585388183594 and parameters: {'learning_rate': 0.053292550181133436, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:47:01,769] Trial 55 finished with value: 0.2679789066314697 and parameters: {'learning_rate': 0.09485242004598596, 'batch_size': 16, 'num_heads': 2, 'key_dim': 16, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:47:07,207] Trial 56 finished with value: 0.1917954385280609 and parameters: {'learning_rate': 0.027807433162594288, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:47:17,562] Trial 57 finished with value: 0.19601033627986908 and parameters: {'learning_rate': 0.03678381982587486, 'batch_size': 16, 'num_heads': 5, 'key_dim': 48, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:47:23,440] Trial 58 finished with value: 0.5221219062805176 and parameters: {'learning_rate': 0.0001635700862955063, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 96}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:47:28,383] Trial 59 finished with value: 0.208311066031456 and parameters: {'learning_rate': 0.04444437601779549, 'batch_size': 128, 'num_heads': 4, 'key_dim': 16, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:47:33,409] Trial 60 finished with value: 0.21911755204200745 and parameters: {'learning_rate': 0.060843101012186644, 'batch_size': 64, 'num_heads': 3, 'key_dim': 32, 'ff_units': 128}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:47:39,025] Trial 61 finished with value: 0.22946158051490784 and parameters: {'learning_rate': 0.025922754325551328, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:47:44,700] Trial 62 finished with value: 0.21737515926361084 and parameters: {'learning_rate': 0.030814674218851545, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 10 with value: 0.16900095343589783.\n",
      "[I 2024-12-18 17:47:50,276] Trial 63 finished with value: 0.15890230238437653 and parameters: {'learning_rate': 0.08169552603399151, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:47:55,804] Trial 64 finished with value: 0.23047034442424774 and parameters: {'learning_rate': 0.08317427980377887, 'batch_size': 16, 'num_heads': 2, 'key_dim': 16, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:48:01,782] Trial 65 finished with value: 0.20793448388576508 and parameters: {'learning_rate': 0.06672096205398322, 'batch_size': 16, 'num_heads': 3, 'key_dim': 32, 'ff_units': 96}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:48:07,613] Trial 66 finished with value: 0.16975180804729462 and parameters: {'learning_rate': 0.09579664239866365, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:48:13,184] Trial 67 finished with value: 0.19721835851669312 and parameters: {'learning_rate': 0.09958703388457096, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:48:18,394] Trial 68 finished with value: 0.2193857878446579 and parameters: {'learning_rate': 0.054312186934595906, 'batch_size': 32, 'num_heads': 3, 'key_dim': 16, 'ff_units': 96}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:48:25,619] Trial 69 finished with value: 0.19523483514785767 and parameters: {'learning_rate': 0.044939994328194115, 'batch_size': 16, 'num_heads': 6, 'key_dim': 48, 'ff_units': 32}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:48:31,324] Trial 70 finished with value: 0.2194964438676834 and parameters: {'learning_rate': 0.08583480865954994, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 96}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:48:36,861] Trial 71 finished with value: 0.20939986407756805 and parameters: {'learning_rate': 0.0703816086314939, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:48:42,419] Trial 72 finished with value: 0.20435695350170135 and parameters: {'learning_rate': 0.058325038488550765, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:48:47,871] Trial 73 finished with value: 0.3014257848262787 and parameters: {'learning_rate': 0.08001791564131175, 'batch_size': 16, 'num_heads': 2, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:48:53,217] Trial 74 finished with value: 0.20815128087997437 and parameters: {'learning_rate': 0.04638960413940909, 'batch_size': 16, 'num_heads': 2, 'key_dim': 16, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:49:00,556] Trial 75 finished with value: 0.17668142914772034 and parameters: {'learning_rate': 0.0996489663208454, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:49:07,564] Trial 76 finished with value: 0.16559864580631256 and parameters: {'learning_rate': 0.08386469253202501, 'batch_size': 16, 'num_heads': 7, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:49:14,945] Trial 77 finished with value: 0.17070578038692474 and parameters: {'learning_rate': 0.09983695989563969, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:49:22,206] Trial 78 finished with value: 0.2599923610687256 and parameters: {'learning_rate': 0.08262679033202804, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:49:29,181] Trial 79 finished with value: 0.19827905297279358 and parameters: {'learning_rate': 0.09477115744583317, 'batch_size': 128, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:49:36,218] Trial 80 finished with value: 0.1997048258781433 and parameters: {'learning_rate': 0.06184153022548751, 'batch_size': 16, 'num_heads': 7, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:49:44,644] Trial 81 finished with value: 0.2775818109512329 and parameters: {'learning_rate': 0.07553881252515245, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:49:52,362] Trial 82 finished with value: 0.17235374450683594 and parameters: {'learning_rate': 0.09919470036370634, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 63 with value: 0.15890230238437653.\n",
      "[I 2024-12-18 17:49:59,874] Trial 83 finished with value: 0.15792414546012878 and parameters: {'learning_rate': 0.08348863696073565, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 83 with value: 0.15792414546012878.\n",
      "[I 2024-12-18 17:50:08,446] Trial 84 finished with value: 0.22163940966129303 and parameters: {'learning_rate': 0.06874366229097924, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 83 with value: 0.15792414546012878.\n",
      "[I 2024-12-18 17:50:15,263] Trial 85 finished with value: 0.3882865607738495 and parameters: {'learning_rate': 0.0019246988341516725, 'batch_size': 64, 'num_heads': 7, 'key_dim': 32, 'ff_units': 64}. Best is trial 83 with value: 0.15792414546012878.\n",
      "[I 2024-12-18 17:50:24,076] Trial 86 finished with value: 0.22126264870166779 and parameters: {'learning_rate': 0.08158922322885562, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 83 with value: 0.15792414546012878.\n",
      "[I 2024-12-18 17:50:32,203] Trial 87 finished with value: 0.1880897581577301 and parameters: {'learning_rate': 0.0556334750744442, 'batch_size': 32, 'num_heads': 8, 'key_dim': 32, 'ff_units': 32}. Best is trial 83 with value: 0.15792414546012878.\n",
      "[I 2024-12-18 17:50:40,102] Trial 88 finished with value: 0.18637481331825256 and parameters: {'learning_rate': 0.097724957561305, 'batch_size': 16, 'num_heads': 7, 'key_dim': 32, 'ff_units': 64}. Best is trial 83 with value: 0.15792414546012878.\n",
      "[I 2024-12-18 17:50:47,882] Trial 89 finished with value: 0.1717623621225357 and parameters: {'learning_rate': 0.06633651206926915, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 83 with value: 0.15792414546012878.\n",
      "[I 2024-12-18 17:50:55,113] Trial 90 finished with value: 0.18987303972244263 and parameters: {'learning_rate': 0.041439269900492355, 'batch_size': 16, 'num_heads': 7, 'key_dim': 32, 'ff_units': 64}. Best is trial 83 with value: 0.15792414546012878.\n",
      "[I 2024-12-18 17:51:02,634] Trial 91 finished with value: 0.24244925379753113 and parameters: {'learning_rate': 0.06628929888814532, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 83 with value: 0.15792414546012878.\n",
      "[I 2024-12-18 17:51:10,077] Trial 92 finished with value: 0.1285320222377777 and parameters: {'learning_rate': 0.07936660427759401, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 92 with value: 0.1285320222377777.\n",
      "[I 2024-12-18 17:51:17,504] Trial 93 finished with value: 0.16237659752368927 and parameters: {'learning_rate': 0.07760697392541424, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 92 with value: 0.1285320222377777.\n",
      "[I 2024-12-18 17:51:24,885] Trial 94 finished with value: 0.2389412373304367 and parameters: {'learning_rate': 0.08014709516545622, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 92 with value: 0.1285320222377777.\n",
      "[I 2024-12-18 17:51:32,436] Trial 95 finished with value: 0.20968429744243622 and parameters: {'learning_rate': 0.05200937573912274, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 92 with value: 0.1285320222377777.\n",
      "[I 2024-12-18 17:51:40,994] Trial 96 finished with value: 0.1985168159008026 and parameters: {'learning_rate': 0.07186926956173766, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 92 with value: 0.1285320222377777.\n",
      "[I 2024-12-18 17:51:48,826] Trial 97 finished with value: 0.20586727559566498 and parameters: {'learning_rate': 0.08470744307973231, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}. Best is trial 92 with value: 0.1285320222377777.\n",
      "[I 2024-12-18 17:51:55,925] Trial 98 finished with value: 0.2202163189649582 and parameters: {'learning_rate': 0.032162788923390424, 'batch_size': 16, 'num_heads': 7, 'key_dim': 32, 'ff_units': 64}. Best is trial 92 with value: 0.1285320222377777.\n",
      "[I 2024-12-18 17:52:02,830] Trial 99 finished with value: 0.2239355891942978 and parameters: {'learning_rate': 0.06815305223135867, 'batch_size': 128, 'num_heads': 6, 'key_dim': 32, 'ff_units': 64}. Best is trial 92 with value: 0.1285320222377777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Transformer parameters: {'learning_rate': 0.07936660427759401, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}\n"
     ]
    }
   ],
   "source": [
    "study_transformer = optuna.create_study(direction='minimize')\n",
    "study_transformer.optimize(lambda trial: objective(trial, model_type='transformer'), n_trials=100)\n",
    "print(\"Best Transformer parameters:\", study_transformer.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d286e747-9eac-4703-9116-b5997baec16e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7148d71d-7e01-42a2-b9cf-6c2d7eb223da",
   "metadata": {},
   "source": [
    " Best is trial 92 with value: 0.1285320222377777. Best Transformer parameters: {'learning_rate': 0.07936660427759401, 'batch_size': 16, 'num_heads': 8, 'key_dim': 32, 'ff_units': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1477768-718f-4901-9996-4db81c0aa892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de3d1e9-c36e-424f-b9c8-b4203132863a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 17:52:02,838] A new study created in memory with name: no-name-29a81bde-972e-4d3e-b0c5-163b7f264302\n",
      "C:\\Users\\Kuzey\\AppData\\Local\\Temp\\ipykernel_12028\\3026521219.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
      "[I 2024-12-18 17:52:05,465] Trial 0 finished with value: 0.004945939872413874 and parameters: {'learning_rate': 0.001423770805411114, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:09,382] Trial 1 finished with value: 0.008734517730772495 and parameters: {'learning_rate': 0.0010308829984158282, 'batch_size': 64, 'num_layers': 2, 'units': 160}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:13,702] Trial 2 finished with value: 0.009188531897962093 and parameters: {'learning_rate': 0.007113998709574925, 'batch_size': 64, 'num_layers': 3, 'units': 192}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:16,909] Trial 3 finished with value: 0.22921808063983917 and parameters: {'learning_rate': 0.07744113291952034, 'batch_size': 16, 'num_layers': 1, 'units': 224}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:19,572] Trial 4 finished with value: 0.03659443557262421 and parameters: {'learning_rate': 0.0024496854636348077, 'batch_size': 128, 'num_layers': 1, 'units': 96}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:23,750] Trial 5 finished with value: 0.014693809673190117 and parameters: {'learning_rate': 0.005833737217751569, 'batch_size': 16, 'num_layers': 3, 'units': 64}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:27,188] Trial 6 finished with value: 0.017052296549081802 and parameters: {'learning_rate': 0.02062896348608934, 'batch_size': 128, 'num_layers': 2, 'units': 192}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:30,888] Trial 7 finished with value: 0.22362938523292542 and parameters: {'learning_rate': 0.0592302612410759, 'batch_size': 64, 'num_layers': 3, 'units': 96}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:34,894] Trial 8 finished with value: 0.2771877646446228 and parameters: {'learning_rate': 0.06439139276608384, 'batch_size': 32, 'num_layers': 3, 'units': 128}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:38,534] Trial 9 finished with value: 0.019653400406241417 and parameters: {'learning_rate': 0.006596186586447301, 'batch_size': 128, 'num_layers': 2, 'units': 224}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:41,043] Trial 10 finished with value: 0.5429289937019348 and parameters: {'learning_rate': 0.00014701681315942334, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:44,440] Trial 11 finished with value: 0.008410068228840828 and parameters: {'learning_rate': 0.0008052302570277827, 'batch_size': 64, 'num_layers': 2, 'units': 160}. Best is trial 0 with value: 0.004945939872413874.\n",
      "[I 2024-12-18 17:52:47,375] Trial 12 finished with value: 0.0040169223211705685 and parameters: {'learning_rate': 0.0004936904951144673, 'batch_size': 32, 'num_layers': 2, 'units': 32}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:52:53,996] Trial 13 finished with value: 0.2863542437553406 and parameters: {'learning_rate': 0.00024005740876780637, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:52:56,683] Trial 14 finished with value: 0.021686051040887833 and parameters: {'learning_rate': 0.0004682204954007234, 'batch_size': 32, 'num_layers': 1, 'units': 64}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:52:59,746] Trial 15 finished with value: 0.009742890484631062 and parameters: {'learning_rate': 0.001743292016697225, 'batch_size': 32, 'num_layers': 2, 'units': 32}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:02,890] Trial 16 finished with value: 0.04242032766342163 and parameters: {'learning_rate': 0.00038565632557702916, 'batch_size': 32, 'num_layers': 1, 'units': 96}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:06,313] Trial 17 finished with value: 0.028154602274298668 and parameters: {'learning_rate': 0.00013341194450627265, 'batch_size': 32, 'num_layers': 2, 'units': 64}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:09,344] Trial 18 finished with value: 0.004364457447081804 and parameters: {'learning_rate': 0.0010565305948723052, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:14,069] Trial 19 finished with value: 0.008303665556013584 and parameters: {'learning_rate': 0.0005799629227525943, 'batch_size': 16, 'num_layers': 2, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:18,227] Trial 20 finished with value: 0.00553771061822772 and parameters: {'learning_rate': 0.00029242651826160196, 'batch_size': 32, 'num_layers': 2, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:20,888] Trial 21 finished with value: 0.0052189636044204235 and parameters: {'learning_rate': 0.0014622947215611945, 'batch_size': 32, 'num_layers': 1, 'units': 128}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:23,437] Trial 22 finished with value: 0.00736790569499135 and parameters: {'learning_rate': 0.003695577574780923, 'batch_size': 32, 'num_layers': 1, 'units': 64}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:25,891] Trial 23 finished with value: 0.03174255043268204 and parameters: {'learning_rate': 0.0009249254954352362, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:28,604] Trial 24 finished with value: 0.011213818565011024 and parameters: {'learning_rate': 0.0033235464933343696, 'batch_size': 32, 'num_layers': 1, 'units': 192}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:31,290] Trial 25 finished with value: 0.004883239511400461 and parameters: {'learning_rate': 0.001600113606296852, 'batch_size': 32, 'num_layers': 1, 'units': 96}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:33,949] Trial 26 finished with value: 0.014082051813602448 and parameters: {'learning_rate': 0.0006761930347139517, 'batch_size': 32, 'num_layers': 1, 'units': 128}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:36,877] Trial 27 finished with value: 0.013791361823678017 and parameters: {'learning_rate': 0.013549175104596856, 'batch_size': 128, 'num_layers': 2, 'units': 96}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:41,299] Trial 28 finished with value: 0.00735233910381794 and parameters: {'learning_rate': 0.0002682997117829061, 'batch_size': 16, 'num_layers': 2, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:43,992] Trial 29 finished with value: 0.005620535463094711 and parameters: {'learning_rate': 0.0020445859833341964, 'batch_size': 32, 'num_layers': 1, 'units': 160}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:47,503] Trial 30 finished with value: 0.00886224489659071 and parameters: {'learning_rate': 0.0013998426031730953, 'batch_size': 32, 'num_layers': 3, 'units': 64}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:50,013] Trial 31 finished with value: 0.06837715953588486 and parameters: {'learning_rate': 0.001106446099145287, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:52,346] Trial 32 finished with value: 0.041270364075899124 and parameters: {'learning_rate': 0.0010322720419038893, 'batch_size': 64, 'num_layers': 1, 'units': 64}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:54,762] Trial 33 finished with value: 0.006917548831552267 and parameters: {'learning_rate': 0.0043031549346180835, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:53:57,359] Trial 34 finished with value: 0.006514199078083038 and parameters: {'learning_rate': 0.00241443263712926, 'batch_size': 32, 'num_layers': 1, 'units': 96}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:00,516] Trial 35 finished with value: 0.00631748279556632 and parameters: {'learning_rate': 0.0004736865102392972, 'batch_size': 16, 'num_layers': 1, 'units': 192}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:03,033] Trial 36 finished with value: 0.010333824902772903 and parameters: {'learning_rate': 0.012680180519246529, 'batch_size': 64, 'num_layers': 1, 'units': 160}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:06,223] Trial 37 finished with value: 0.15418919920921326 and parameters: {'learning_rate': 0.0002010020283983804, 'batch_size': 128, 'num_layers': 3, 'units': 64}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:08,898] Trial 38 finished with value: 0.004379932768642902 and parameters: {'learning_rate': 0.0012633041972282583, 'batch_size': 32, 'num_layers': 1, 'units': 128}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:11,499] Trial 39 finished with value: 0.02219180017709732 and parameters: {'learning_rate': 0.0006612622505155172, 'batch_size': 32, 'num_layers': 1, 'units': 128}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:14,761] Trial 40 finished with value: 0.013872873969376087 and parameters: {'learning_rate': 0.0013007901446297793, 'batch_size': 32, 'num_layers': 2, 'units': 128}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:17,327] Trial 41 finished with value: 0.00523575022816658 and parameters: {'learning_rate': 0.0023218014016918097, 'batch_size': 32, 'num_layers': 1, 'units': 96}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:20,195] Trial 42 finished with value: 0.009240965358912945 and parameters: {'learning_rate': 0.005293133294843749, 'batch_size': 32, 'num_layers': 1, 'units': 160}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:22,587] Trial 43 finished with value: 0.1406487673521042 and parameters: {'learning_rate': 0.00037697717948556814, 'batch_size': 128, 'num_layers': 1, 'units': 96}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:25,027] Trial 44 finished with value: 0.030472975224256516 and parameters: {'learning_rate': 0.000868339126629753, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:29,643] Trial 45 finished with value: 0.009557382203638554 and parameters: {'learning_rate': 0.001664232372697568, 'batch_size': 64, 'num_layers': 3, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:32,403] Trial 46 finished with value: 0.005953758955001831 and parameters: {'learning_rate': 0.002862968934656317, 'batch_size': 32, 'num_layers': 1, 'units': 128}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:35,868] Trial 47 finished with value: 0.0074692233465611935 and parameters: {'learning_rate': 0.009748947223696984, 'batch_size': 32, 'num_layers': 2, 'units': 96}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:40,072] Trial 48 finished with value: 0.011931377463042736 and parameters: {'learning_rate': 0.0005433097110629128, 'batch_size': 16, 'num_layers': 2, 'units': 160}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:42,464] Trial 49 finished with value: 0.03349311277270317 and parameters: {'learning_rate': 0.0008087873176908822, 'batch_size': 32, 'num_layers': 1, 'units': 32}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:45,135] Trial 50 finished with value: 0.06221722811460495 and parameters: {'learning_rate': 0.00018565408521832217, 'batch_size': 32, 'num_layers': 1, 'units': 192}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:47,731] Trial 51 finished with value: 0.005939191672950983 and parameters: {'learning_rate': 0.0014663152273032528, 'batch_size': 32, 'num_layers': 1, 'units': 128}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:50,487] Trial 52 finished with value: 0.007008453831076622 and parameters: {'learning_rate': 0.001774641469102594, 'batch_size': 32, 'num_layers': 1, 'units': 128}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:53,399] Trial 53 finished with value: 0.004496124107390642 and parameters: {'learning_rate': 0.0011121541443757218, 'batch_size': 32, 'num_layers': 1, 'units': 160}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:56,316] Trial 54 finished with value: 0.004747127182781696 and parameters: {'learning_rate': 0.001075104412983838, 'batch_size': 32, 'num_layers': 1, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:54:59,194] Trial 55 finished with value: 0.0043530212715268135 and parameters: {'learning_rate': 0.0011224547780530967, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:02,029] Trial 56 finished with value: 0.0351983867585659 and parameters: {'learning_rate': 0.00034562035919586125, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:04,804] Trial 57 finished with value: 0.00436019292101264 and parameters: {'learning_rate': 0.0010940848180498906, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:07,511] Trial 58 finished with value: 0.00955364853143692 and parameters: {'learning_rate': 0.036483390648949746, 'batch_size': 128, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:11,604] Trial 59 finished with value: 0.007026785984635353 and parameters: {'learning_rate': 0.0006994913975159129, 'batch_size': 32, 'num_layers': 2, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:14,200] Trial 60 finished with value: 0.021640045568346977 and parameters: {'learning_rate': 0.00047316754034489516, 'batch_size': 64, 'num_layers': 1, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:17,206] Trial 61 finished with value: 0.005148212891072035 and parameters: {'learning_rate': 0.0011678761038026806, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:19,988] Trial 62 finished with value: 0.004643188789486885 and parameters: {'learning_rate': 0.0009846096939527943, 'batch_size': 32, 'num_layers': 1, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:22,825] Trial 63 finished with value: 0.004627857357263565 and parameters: {'learning_rate': 0.0007923995006880646, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:25,791] Trial 64 finished with value: 0.007238422520458698 and parameters: {'learning_rate': 0.0006930714489624969, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:28,530] Trial 65 finished with value: 0.010484687983989716 and parameters: {'learning_rate': 0.0005438248637411536, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:31,619] Trial 66 finished with value: 0.00988581869751215 and parameters: {'learning_rate': 0.0020787402604106877, 'batch_size': 16, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:34,350] Trial 67 finished with value: 0.00462116114795208 and parameters: {'learning_rate': 0.0008298759487073412, 'batch_size': 32, 'num_layers': 1, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:37,317] Trial 68 finished with value: 0.007054068613797426 and parameters: {'learning_rate': 0.002745487515381221, 'batch_size': 32, 'num_layers': 1, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:40,099] Trial 69 finished with value: 0.02647922933101654 and parameters: {'learning_rate': 0.00040307840392414556, 'batch_size': 32, 'num_layers': 1, 'units': 192}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:44,896] Trial 70 finished with value: 0.005587519146502018 and parameters: {'learning_rate': 0.0012398703204529202, 'batch_size': 32, 'num_layers': 3, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:47,759] Trial 71 finished with value: 0.005328174214810133 and parameters: {'learning_rate': 0.0008044345929878763, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:50,498] Trial 72 finished with value: 0.020634213462471962 and parameters: {'learning_rate': 0.0003231904302636928, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:53,248] Trial 73 finished with value: 0.00741904741153121 and parameters: {'learning_rate': 0.0006225124200386219, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:55,906] Trial 74 finished with value: 0.006590254604816437 and parameters: {'learning_rate': 0.0008963300594685298, 'batch_size': 32, 'num_layers': 1, 'units': 192}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:55:58,650] Trial 75 finished with value: 0.008407531306147575 and parameters: {'learning_rate': 0.0018631403531053647, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:01,363] Trial 76 finished with value: 0.006395632401108742 and parameters: {'learning_rate': 0.0013587045834417136, 'batch_size': 32, 'num_layers': 1, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:03,873] Trial 77 finished with value: 0.1555304080247879 and parameters: {'learning_rate': 0.0004290983753936172, 'batch_size': 128, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:06,478] Trial 78 finished with value: 0.007009230554103851 and parameters: {'learning_rate': 0.0007374078476033268, 'batch_size': 32, 'num_layers': 1, 'units': 192}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:09,011] Trial 79 finished with value: 0.0183098167181015 and parameters: {'learning_rate': 0.0005564288369650847, 'batch_size': 64, 'num_layers': 1, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:13,364] Trial 80 finished with value: 0.006771469488739967 and parameters: {'learning_rate': 0.0002625226498531906, 'batch_size': 16, 'num_layers': 2, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:16,072] Trial 81 finished with value: 0.004584070295095444 and parameters: {'learning_rate': 0.0009828404163974881, 'batch_size': 32, 'num_layers': 1, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:18,898] Trial 82 finished with value: 0.004255229141563177 and parameters: {'learning_rate': 0.000991784361961643, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:21,705] Trial 83 finished with value: 0.004301709122955799 and parameters: {'learning_rate': 0.0011016313730267085, 'batch_size': 32, 'num_layers': 1, 'units': 224}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:24,437] Trial 84 finished with value: 0.004365738946944475 and parameters: {'learning_rate': 0.001012490440210527, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:27,156] Trial 85 finished with value: 0.1935790330171585 and parameters: {'learning_rate': 0.00010515977167932282, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:29,887] Trial 86 finished with value: 0.005516889970749617 and parameters: {'learning_rate': 0.0015311590986017381, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:33,705] Trial 87 finished with value: 0.012966255657374859 and parameters: {'learning_rate': 0.001165937273735226, 'batch_size': 32, 'num_layers': 2, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:36,499] Trial 88 finished with value: 0.006652588024735451 and parameters: {'learning_rate': 0.002248947101616314, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:41,714] Trial 89 finished with value: 0.010213878937065601 and parameters: {'learning_rate': 0.0018261758072472777, 'batch_size': 32, 'num_layers': 3, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:44,347] Trial 90 finished with value: 0.004489473532885313 and parameters: {'learning_rate': 0.0010394019819325113, 'batch_size': 32, 'num_layers': 1, 'units': 160}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:47,086] Trial 91 finished with value: 0.012714420445263386 and parameters: {'learning_rate': 0.003617234359792995, 'batch_size': 32, 'num_layers': 1, 'units': 160}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:49,673] Trial 92 finished with value: 0.0053221494890749454 and parameters: {'learning_rate': 0.0013563683052608025, 'batch_size': 32, 'num_layers': 1, 'units': 160}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:52,245] Trial 93 finished with value: 0.004549771081656218 and parameters: {'learning_rate': 0.0010577344776567538, 'batch_size': 32, 'num_layers': 1, 'units': 160}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:54,851] Trial 94 finished with value: 0.005377956200391054 and parameters: {'learning_rate': 0.001227782199559096, 'batch_size': 32, 'num_layers': 1, 'units': 192}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:56:57,327] Trial 95 finished with value: 0.03379346430301666 and parameters: {'learning_rate': 0.0009695868832591388, 'batch_size': 128, 'num_layers': 1, 'units': 160}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:57:00,063] Trial 96 finished with value: 0.012776578776538372 and parameters: {'learning_rate': 0.000620716618593092, 'batch_size': 32, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:57:02,632] Trial 97 finished with value: 0.02173357456922531 and parameters: {'learning_rate': 0.0004907749109166621, 'batch_size': 32, 'num_layers': 1, 'units': 128}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:57:04,937] Trial 98 finished with value: 0.01260694395750761 and parameters: {'learning_rate': 0.0015475595933574936, 'batch_size': 64, 'num_layers': 1, 'units': 64}. Best is trial 12 with value: 0.0040169223211705685.\n",
      "[I 2024-12-18 17:57:08,105] Trial 99 finished with value: 0.008633137680590153 and parameters: {'learning_rate': 0.00268010519384361, 'batch_size': 16, 'num_layers': 1, 'units': 256}. Best is trial 12 with value: 0.0040169223211705685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Neural Network parameters: {'learning_rate': 0.0004936904951144673, 'batch_size': 32, 'num_layers': 2, 'units': 32}\n"
     ]
    }
   ],
   "source": [
    "study_nn = optuna.create_study(direction='minimize')\n",
    "study_nn.optimize(lambda trial: objective(trial, model_type='neural_net'), n_trials=100)\n",
    "print(\"Best Neural Network parameters:\", study_nn.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3327c03c-7061-4526-bcb4-8d78ba5f64b3",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82db049-b7e2-4258-af56-4ada45aee988",
   "metadata": {},
   "source": [
    "Best is trial 12 with value: 0.0040169223211705685. Best Neural Network parameters: {'learning_rate': 0.0004936904951144673, 'batch_size': 32, 'num_layers': 2, 'units': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08653131-a843-45dc-9216-5b488513f5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 17:57:08,116] A new study created in memory with name: no-name-a0f07873-ad21-412c-9cd2-5ce9b3762516\n",
      "C:\\Users\\Kuzey\\AppData\\Local\\Temp\\ipykernel_12028\\3026521219.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
      "[I 2024-12-18 17:57:13,659] Trial 0 finished with value: 0.040273748338222504 and parameters: {'learning_rate': 0.0029256367641638816, 'batch_size': 16, 'num_layers': 2, 'units': 256, 'activation': 'sigmoid'}. Best is trial 0 with value: 0.040273748338222504.\n",
      "[I 2024-12-18 17:57:16,888] Trial 1 finished with value: 0.006168432999402285 and parameters: {'learning_rate': 0.0019523972311138546, 'batch_size': 32, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 1 with value: 0.006168432999402285.\n",
      "[I 2024-12-18 17:57:20,303] Trial 2 finished with value: 0.006886634044349194 and parameters: {'learning_rate': 0.03433098230490917, 'batch_size': 32, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 1 with value: 0.006168432999402285.\n",
      "[I 2024-12-18 17:57:23,497] Trial 3 finished with value: 0.00586572615429759 and parameters: {'learning_rate': 0.0008051985998590871, 'batch_size': 16, 'num_layers': 1, 'units': 32, 'activation': 'tanh'}. Best is trial 3 with value: 0.00586572615429759.\n",
      "[I 2024-12-18 17:57:26,612] Trial 4 finished with value: 0.17165395617485046 and parameters: {'learning_rate': 0.023313128814694346, 'batch_size': 32, 'num_layers': 1, 'units': 96, 'activation': 'sigmoid'}. Best is trial 3 with value: 0.00586572615429759.\n",
      "[I 2024-12-18 17:57:31,284] Trial 5 finished with value: 0.1995554119348526 and parameters: {'learning_rate': 0.00015718009230179656, 'batch_size': 32, 'num_layers': 2, 'units': 224, 'activation': 'sigmoid'}. Best is trial 3 with value: 0.00586572615429759.\n",
      "[I 2024-12-18 17:57:34,995] Trial 6 finished with value: 0.14068806171417236 and parameters: {'learning_rate': 0.009745958976060327, 'batch_size': 128, 'num_layers': 1, 'units': 256, 'activation': 'sigmoid'}. Best is trial 3 with value: 0.00586572615429759.\n",
      "[I 2024-12-18 17:57:38,517] Trial 7 finished with value: 0.016285264864563942 and parameters: {'learning_rate': 0.03889311492685566, 'batch_size': 32, 'num_layers': 2, 'units': 64, 'activation': 'relu'}. Best is trial 3 with value: 0.00586572615429759.\n",
      "[I 2024-12-18 17:57:43,239] Trial 8 finished with value: 0.19711312651634216 and parameters: {'learning_rate': 0.00026926762049444777, 'batch_size': 64, 'num_layers': 3, 'units': 160, 'activation': 'sigmoid'}. Best is trial 3 with value: 0.00586572615429759.\n",
      "[I 2024-12-18 17:57:47,512] Trial 9 finished with value: 0.007761563174426556 and parameters: {'learning_rate': 0.0002879547101300769, 'batch_size': 32, 'num_layers': 3, 'units': 128, 'activation': 'tanh'}. Best is trial 3 with value: 0.00586572615429759.\n",
      "[I 2024-12-18 17:57:51,535] Trial 10 finished with value: 0.008128378540277481 and parameters: {'learning_rate': 0.0007912188744015748, 'batch_size': 16, 'num_layers': 1, 'units': 160, 'activation': 'relu'}. Best is trial 3 with value: 0.00586572615429759.\n",
      "[I 2024-12-18 17:57:54,815] Trial 11 finished with value: 0.005109694320708513 and parameters: {'learning_rate': 0.0016151686388811554, 'batch_size': 16, 'num_layers': 1, 'units': 32, 'activation': 'tanh'}. Best is trial 11 with value: 0.005109694320708513.\n",
      "[I 2024-12-18 17:57:58,186] Trial 12 finished with value: 0.005669066216796637 and parameters: {'learning_rate': 0.0009722571603907468, 'batch_size': 16, 'num_layers': 1, 'units': 64, 'activation': 'tanh'}. Best is trial 11 with value: 0.005109694320708513.\n",
      "[I 2024-12-18 17:58:01,924] Trial 13 finished with value: 0.028744202107191086 and parameters: {'learning_rate': 0.00824268690624535, 'batch_size': 16, 'num_layers': 1, 'units': 96, 'activation': 'tanh'}. Best is trial 11 with value: 0.005109694320708513.\n",
      "[I 2024-12-18 17:58:05,317] Trial 14 finished with value: 0.004597577732056379 and parameters: {'learning_rate': 0.0010504909369437893, 'batch_size': 16, 'num_layers': 1, 'units': 64, 'activation': 'tanh'}. Best is trial 14 with value: 0.004597577732056379.\n",
      "[I 2024-12-18 17:58:08,207] Trial 15 finished with value: 0.004938527476042509 and parameters: {'learning_rate': 0.00606883893282261, 'batch_size': 64, 'num_layers': 1, 'units': 96, 'activation': 'tanh'}. Best is trial 14 with value: 0.004597577732056379.\n",
      "[I 2024-12-18 17:58:11,554] Trial 16 finished with value: 0.005579065531492233 and parameters: {'learning_rate': 0.007571058991219882, 'batch_size': 64, 'num_layers': 1, 'units': 128, 'activation': 'tanh'}. Best is trial 14 with value: 0.004597577732056379.\n",
      "[I 2024-12-18 17:58:16,296] Trial 17 finished with value: 0.18066948652267456 and parameters: {'learning_rate': 0.07354957966177905, 'batch_size': 64, 'num_layers': 3, 'units': 96, 'activation': 'relu'}. Best is trial 14 with value: 0.004597577732056379.\n",
      "[I 2024-12-18 17:58:19,905] Trial 18 finished with value: 0.007784615270793438 and parameters: {'learning_rate': 0.004271018662843441, 'batch_size': 128, 'num_layers': 1, 'units': 192, 'activation': 'tanh'}. Best is trial 14 with value: 0.004597577732056379.\n",
      "[I 2024-12-18 17:58:23,147] Trial 19 finished with value: 0.0045827762223780155 and parameters: {'learning_rate': 0.012871068906889825, 'batch_size': 64, 'num_layers': 2, 'units': 64, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:58:26,212] Trial 20 finished with value: 0.01532324030995369 and parameters: {'learning_rate': 0.013757336018644468, 'batch_size': 64, 'num_layers': 2, 'units': 64, 'activation': 'relu'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:58:29,556] Trial 21 finished with value: 0.006340364925563335 and parameters: {'learning_rate': 0.004109055138051698, 'batch_size': 64, 'num_layers': 2, 'units': 96, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:58:33,089] Trial 22 finished with value: 0.016390157863497734 and parameters: {'learning_rate': 0.0213021892301285, 'batch_size': 64, 'num_layers': 3, 'units': 64, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:58:36,029] Trial 23 finished with value: 0.005474674515426159 and parameters: {'learning_rate': 0.005629569941395275, 'batch_size': 64, 'num_layers': 1, 'units': 128, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:58:39,102] Trial 24 finished with value: 0.005964110605418682 and parameters: {'learning_rate': 0.00250984842692901, 'batch_size': 64, 'num_layers': 2, 'units': 64, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:58:41,842] Trial 25 finished with value: 0.006079663522541523 and parameters: {'learning_rate': 0.0004244078089881511, 'batch_size': 128, 'num_layers': 1, 'units': 96, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:58:45,009] Trial 26 finished with value: 0.005766642279922962 and parameters: {'learning_rate': 0.0015467292104863284, 'batch_size': 64, 'num_layers': 2, 'units': 64, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:58:48,123] Trial 27 finished with value: 0.004888213239610195 and parameters: {'learning_rate': 0.016726949692087954, 'batch_size': 64, 'num_layers': 1, 'units': 128, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:58:53,562] Trial 28 finished with value: 0.17098161578178406 and parameters: {'learning_rate': 0.06496345575958448, 'batch_size': 16, 'num_layers': 2, 'units': 192, 'activation': 'relu'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:58:59,212] Trial 29 finished with value: 0.01779216341674328 and parameters: {'learning_rate': 0.014129731564964451, 'batch_size': 16, 'num_layers': 3, 'units': 160, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:59:02,217] Trial 30 finished with value: 0.19802972674369812 and parameters: {'learning_rate': 0.09829826621748827, 'batch_size': 128, 'num_layers': 1, 'units': 128, 'activation': 'sigmoid'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:59:10,699] Trial 31 finished with value: 0.0070544518530368805 and parameters: {'learning_rate': 0.01409307914195815, 'batch_size': 64, 'num_layers': 1, 'units': 96, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:59:13,963] Trial 32 finished with value: 0.004850368015468121 and parameters: {'learning_rate': 0.0028218169839686344, 'batch_size': 64, 'num_layers': 1, 'units': 128, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:59:17,615] Trial 33 finished with value: 0.00602993369102478 and parameters: {'learning_rate': 0.002188720516886307, 'batch_size': 64, 'num_layers': 1, 'units': 192, 'activation': 'tanh'}. Best is trial 19 with value: 0.0045827762223780155.\n",
      "[I 2024-12-18 17:59:20,716] Trial 34 finished with value: 0.00433149142190814 and parameters: {'learning_rate': 0.0010472772756695233, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 34 with value: 0.00433149142190814.\n",
      "[I 2024-12-18 17:59:23,928] Trial 35 finished with value: 0.004630196839570999 and parameters: {'learning_rate': 0.0005539508354535884, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 34 with value: 0.00433149142190814.\n",
      "[I 2024-12-18 17:59:27,829] Trial 36 finished with value: 0.0059443870559334755 and parameters: {'learning_rate': 0.000525822293321032, 'batch_size': 16, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 34 with value: 0.00433149142190814.\n",
      "[I 2024-12-18 17:59:30,920] Trial 37 finished with value: 0.013192879036068916 and parameters: {'learning_rate': 0.00011207708124800169, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 34 with value: 0.00433149142190814.\n",
      "[I 2024-12-18 17:59:34,339] Trial 38 finished with value: 0.17809702455997467 and parameters: {'learning_rate': 0.0010920958769408578, 'batch_size': 32, 'num_layers': 2, 'units': 32, 'activation': 'sigmoid'}. Best is trial 34 with value: 0.00433149142190814.\n",
      "[I 2024-12-18 17:59:37,421] Trial 39 finished with value: 0.004315217491239309 and parameters: {'learning_rate': 0.0005623753542385045, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 39 with value: 0.004315217491239309.\n",
      "[I 2024-12-18 17:59:41,195] Trial 40 finished with value: 0.22146615386009216 and parameters: {'learning_rate': 0.000323429081456287, 'batch_size': 16, 'num_layers': 2, 'units': 32, 'activation': 'sigmoid'}. Best is trial 39 with value: 0.004315217491239309.\n",
      "[I 2024-12-18 17:59:44,273] Trial 41 finished with value: 0.0038831636775285006 and parameters: {'learning_rate': 0.0006279188464989444, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 17:59:47,497] Trial 42 finished with value: 0.0052611432038247585 and parameters: {'learning_rate': 0.0006898027951812375, 'batch_size': 64, 'num_layers': 2, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 17:59:50,588] Trial 43 finished with value: 0.004412839654833078 and parameters: {'learning_rate': 0.0014817538446076782, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 17:59:53,709] Trial 44 finished with value: 0.004967228043824434 and parameters: {'learning_rate': 0.0013936547894760091, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 17:59:57,020] Trial 45 finished with value: 0.009198354557156563 and parameters: {'learning_rate': 0.0002547810737964694, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:00,168] Trial 46 finished with value: 0.37912479043006897 and parameters: {'learning_rate': 0.00020547319808004178, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'relu'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:03,645] Trial 47 finished with value: 0.0060423435643315315 and parameters: {'learning_rate': 0.0007501253737820383, 'batch_size': 32, 'num_layers': 2, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:06,618] Trial 48 finished with value: 0.00396184204146266 and parameters: {'learning_rate': 0.00040841902146152394, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:09,621] Trial 49 finished with value: 0.21445804834365845 and parameters: {'learning_rate': 0.0003954158981414197, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'sigmoid'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:15,953] Trial 50 finished with value: 0.005460407584905624 and parameters: {'learning_rate': 0.0005191950311160224, 'batch_size': 128, 'num_layers': 3, 'units': 256, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:19,182] Trial 51 finished with value: 0.004736522678285837 and parameters: {'learning_rate': 0.0010620636958976963, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:22,967] Trial 52 finished with value: 0.004368409048765898 and parameters: {'learning_rate': 0.0012426260453850294, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:26,376] Trial 53 finished with value: 0.005846850574016571 and parameters: {'learning_rate': 0.0013644385706899449, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:29,401] Trial 54 finished with value: 0.004549555946141481 and parameters: {'learning_rate': 0.0018110831822930294, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:32,795] Trial 55 finished with value: 0.005856577772647142 and parameters: {'learning_rate': 0.00018141635715721933, 'batch_size': 64, 'num_layers': 2, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:35,880] Trial 56 finished with value: 0.004648353438824415 and parameters: {'learning_rate': 0.0008488843499033579, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:40,789] Trial 57 finished with value: 0.008714509196579456 and parameters: {'learning_rate': 0.00038367656189869034, 'batch_size': 32, 'num_layers': 2, 'units': 224, 'activation': 'relu'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:43,941] Trial 58 finished with value: 0.005320490803569555 and parameters: {'learning_rate': 0.0006271035002109332, 'batch_size': 64, 'num_layers': 2, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:47,184] Trial 59 finished with value: 0.005008616950362921 and parameters: {'learning_rate': 0.0036358740976119215, 'batch_size': 64, 'num_layers': 2, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:50,355] Trial 60 finished with value: 0.004984430968761444 and parameters: {'learning_rate': 0.0011611700663718967, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:53,883] Trial 61 finished with value: 0.004516181536018848 and parameters: {'learning_rate': 0.0019964053960162377, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:00:57,125] Trial 62 finished with value: 0.004282711073756218 and parameters: {'learning_rate': 0.0008460709269125727, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:01,082] Trial 63 finished with value: 0.005076514091342688 and parameters: {'learning_rate': 0.0009040976706948331, 'batch_size': 64, 'num_layers': 2, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:05,180] Trial 64 finished with value: 0.005078077781945467 and parameters: {'learning_rate': 0.0004589634316289589, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:09,596] Trial 65 finished with value: 0.03431341052055359 and parameters: {'learning_rate': 0.000317642529203192, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:13,914] Trial 66 finished with value: 0.004729811567813158 and parameters: {'learning_rate': 0.0007503066333571738, 'batch_size': 128, 'num_layers': 2, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:18,250] Trial 67 finished with value: 0.01202022098004818 and parameters: {'learning_rate': 0.0012051545431860252, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'relu'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:22,345] Trial 68 finished with value: 0.004151991568505764 and parameters: {'learning_rate': 0.0006334857687958492, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:26,659] Trial 69 finished with value: 0.21494178473949432 and parameters: {'learning_rate': 0.00024807339081933444, 'batch_size': 64, 'num_layers': 2, 'units': 64, 'activation': 'sigmoid'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:31,657] Trial 70 finished with value: 0.00389390648342669 and parameters: {'learning_rate': 0.0006091591868348522, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:36,603] Trial 71 finished with value: 0.004492579959332943 and parameters: {'learning_rate': 0.0006187331491513083, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:41,762] Trial 72 finished with value: 0.00469233887270093 and parameters: {'learning_rate': 0.00045063491852855237, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:46,265] Trial 73 finished with value: 0.0052767167799174786 and parameters: {'learning_rate': 0.000882630465406213, 'batch_size': 32, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:51,581] Trial 74 finished with value: 0.0043284292332828045 and parameters: {'learning_rate': 0.0005917996974124066, 'batch_size': 32, 'num_layers': 3, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:01:56,819] Trial 75 finished with value: 0.005367549601942301 and parameters: {'learning_rate': 0.0003530562721028713, 'batch_size': 32, 'num_layers': 3, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:02:02,975] Trial 76 finished with value: 0.005912113934755325 and parameters: {'learning_rate': 0.0005800864665100538, 'batch_size': 32, 'num_layers': 3, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:02:08,367] Trial 77 finished with value: 0.00652602594345808 and parameters: {'learning_rate': 0.000480676119691649, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:02:13,331] Trial 78 finished with value: 0.004142878111451864 and parameters: {'learning_rate': 0.00022565293661759388, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:02:19,262] Trial 79 finished with value: 0.0067401472479105 and parameters: {'learning_rate': 0.0002085336282027614, 'batch_size': 32, 'num_layers': 3, 'units': 96, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:02:24,392] Trial 80 finished with value: 0.004445960745215416 and parameters: {'learning_rate': 0.00012700039383022456, 'batch_size': 32, 'num_layers': 3, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:02:29,289] Trial 81 finished with value: 0.004392525181174278 and parameters: {'learning_rate': 0.00029619560871913496, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:02:34,592] Trial 82 finished with value: 0.004080857615917921 and parameters: {'learning_rate': 0.00015606751089075805, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:02:39,883] Trial 83 finished with value: 0.0058414526283741 and parameters: {'learning_rate': 0.0001534919169781853, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:02:45,172] Trial 84 finished with value: 0.025908613577485085 and parameters: {'learning_rate': 0.00013758920748482877, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:02:50,403] Trial 85 finished with value: 0.0040281652472913265 and parameters: {'learning_rate': 0.0002266012288024373, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:02:55,587] Trial 86 finished with value: 0.02360711060464382 and parameters: {'learning_rate': 0.00021895115533451605, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'relu'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:03:00,724] Trial 87 finished with value: 0.219273179769516 and parameters: {'learning_rate': 0.00026108484115658766, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'sigmoid'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:03:06,131] Trial 88 finished with value: 0.00899452157318592 and parameters: {'learning_rate': 0.00010381603237314529, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:03:14,400] Trial 89 finished with value: 0.004748429171741009 and parameters: {'learning_rate': 0.000186926177181454, 'batch_size': 128, 'num_layers': 3, 'units': 224, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:03:20,188] Trial 90 finished with value: 0.003943159710615873 and parameters: {'learning_rate': 0.0003690982391177431, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:03:25,131] Trial 91 finished with value: 0.004145623650401831 and parameters: {'learning_rate': 0.0003960441155014737, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:03:30,025] Trial 92 finished with value: 0.004735845141112804 and parameters: {'learning_rate': 0.0003563381290838619, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:03:34,978] Trial 93 finished with value: 0.005684736650437117 and parameters: {'learning_rate': 0.00015818154467214695, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:03:39,947] Trial 94 finished with value: 0.004340898245573044 and parameters: {'learning_rate': 0.00043922989555421663, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:03:44,909] Trial 95 finished with value: 0.003956884611397982 and parameters: {'learning_rate': 0.0003068554104817965, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:03:49,869] Trial 96 finished with value: 0.003917979076504707 and parameters: {'learning_rate': 0.0002314203971069139, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:03:55,012] Trial 97 finished with value: 0.0055642081424593925 and parameters: {'learning_rate': 0.00023840250026396458, 'batch_size': 32, 'num_layers': 3, 'units': 64, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:04:01,458] Trial 98 finished with value: 0.006366845220327377 and parameters: {'learning_rate': 0.0001583487942042355, 'batch_size': 32, 'num_layers': 3, 'units': 160, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n",
      "[I 2024-12-18 18:04:06,366] Trial 99 finished with value: 0.004006411414593458 and parameters: {'learning_rate': 0.0003046018117589693, 'batch_size': 32, 'num_layers': 3, 'units': 32, 'activation': 'tanh'}. Best is trial 41 with value: 0.0038831636775285006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ODE parameters: {'learning_rate': 0.0006279188464989444, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "study_ode = optuna.create_study(direction='minimize')\n",
    "study_ode.optimize(lambda trial: objective(trial, model_type='ode'), n_trials=100)\n",
    "print(\"Best ODE parameters:\", study_ode.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1039aa8-00b0-495e-8e30-ed3faad8de91",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "739bc4f8-8749-4eaf-96f1-b2e9d6bcfb08",
   "metadata": {},
   "source": [
    "Best is trial 41 with value: 0.0038831636775285006. Best ODE parameters: {'learning_rate': 0.0006279188464989444, 'batch_size': 64, 'num_layers': 2, 'units': 32, 'activation': 'tanh'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb90065-176f-4877-967f-8375584e1865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00733cb8-0176-4d9d-b0da-0865603ffa10",
   "metadata": {},
   "source": [
    "Here’s how to use this function to print the architecture for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd9d800-7e51-4f5f-bf97-9e5b6fad3e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53c0ac-a089-43ce-a309-9ab2c0df27ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697fef1-2e35-44a0-90b7-15b79a286d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
