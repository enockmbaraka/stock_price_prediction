{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cac5af2-3057-4a98-9dcf-cd069e84415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Dropout, MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, MultiHeadAttention, LayerNormalization\n",
    "TF_ENABLE_ONEDNN_OPTS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2159ec-c606-4585-859b-a60cc9458eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate synthetic data (e.g., exponential decay)\n",
    "def simulate_ode(k=0.1, y0=1.0, t_max=10, num_points=1000):\n",
    "    t = np.linspace(0, t_max, num_points)\n",
    "    y = y0 * np.exp(-k * t)\n",
    "    return t, y\n",
    "\n",
    "# Create synthetic data\n",
    "t, y = simulate_ode()\n",
    "X = t.reshape(-1, 1)  # Time as input\n",
    "y = y.reshape(-1, 1)  # State as output\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b7581-3fbf-465d-9f37-129ceb8b0fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74e234d7-b087-416a-b0ad-2874c2d74198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def objective(trial, model_type):\n",
    "    # Common hyperparameters\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "\n",
    "    # Define the model based on the type\n",
    "    model = Sequential()\n",
    "    \n",
    "    if model_type == 'rnn':\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "        units = trial.suggest_int('units', 32, 256, step=32)\n",
    "        for _ in range(num_layers):\n",
    "            model.add(SimpleRNN(units, activation='tanh', return_sequences=True if _ < num_layers - 1 else False))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "    elif model_type == 'lstm':\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "        units = trial.suggest_int('units', 32, 256, step=32)\n",
    "        for _ in range(num_layers):\n",
    "            model.add(LSTM(units, activation='tanh', return_sequences=True if _ < num_layers - 1 else False))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "    elif model_type == 'transformer':\n",
    "        num_heads = trial.suggest_int('num_heads', 2, 8)\n",
    "        key_dim = trial.suggest_int('key_dim', 16, 64, step=16)\n",
    "        model.add(MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, input_shape=(None, 1)))\n",
    "        model.add(LayerNormalization())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "    elif model_type == 'neural_net':\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "        units = trial.suggest_int('units', 32, 256, step=32)\n",
    "        for _ in range(num_layers):\n",
    "            model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "    elif model_type == 'ode':\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "        units = trial.suggest_int('units', 32, 256, step=32)\n",
    "        model.add(Dense(units, activation='relu', input_dim=1))\n",
    "        for _ in range(num_layers):\n",
    "            model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dense(1))  # Approximate derivative\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Return the validation loss for Optuna to minimize\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    return val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51f4ba-83ea-452e-8a24-e4f6c70ffde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_rnn = optuna.create_study(direction='minimize')\n",
    "study_rnn.optimize(lambda trial: objective(trial, model_type='rnn'), n_trials=20)\n",
    "print(\"Best RNN parameters:\", study_rnn.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd1561-051c-4092-bddd-096485f27162",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lstm = optuna.create_study(direction='minimize')\n",
    "study_lstm.optimize(lambda trial: objective(trial, model_type='lstm'), n_trials=20)\n",
    "print(\"Best LSTM parameters:\", study_lstm.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a63724a-4988-4b36-8ab7-996a158ebc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_transformer = optuna.create_study(direction='minimize')\n",
    "study_transformer.optimize(lambda trial: objective(trial, model_type='transformer'), n_trials=20)\n",
    "print(\"Best Transformer parameters:\", study_transformer.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3d1e9-c36e-424f-b9c8-b4203132863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_nn = optuna.create_study(direction='minimize')\n",
    "study_nn.optimize(lambda trial: objective(trial, model_type='neural_net'), n_trials=20)\n",
    "print(\"Best Neural Network parameters:\", study_nn.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08653131-a843-45dc-9216-5b488513f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_ode = optuna.create_study(direction='minimize')\n",
    "study_ode.optimize(lambda trial: objective(trial, model_type='ode'), n_trials=20)\n",
    "print(\"Best ODE parameters:\", study_ode.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37caa8-c67b-4e21-8e1e-78bedacab86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using the best RNN model\n",
    "best_rnn_params = study_rnn.best_params\n",
    "print(\"Best RNN Parameters:\", best_rnn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb90065-176f-4877-967f-8375584e1865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00733cb8-0176-4d9d-b0da-0865603ffa10",
   "metadata": {},
   "source": [
    "Hereâ€™s how to use this function to print the architecture for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d36036-8196-450d-b171-0fe366601602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a97aec9-cef4-4061-8a20-84a9308e7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stock_data(csv_path, date_column='date', close_column='close', test_size=0.2, val_size=0.1, time_steps=60):\n",
    "    \"\"\"\n",
    "    Prepares stock market price data for time series modeling.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing the data.\n",
    "        date_column (str): Name of the date column in the CSV.\n",
    "        close_column (str): Name of the closing price column in the CSV.\n",
    "        test_size (float): Proportion of the data for testing.\n",
    "        val_size (float): Proportion of the training data for validation.\n",
    "        time_steps (int): Number of past time steps to use for each sample.\n",
    "    \n",
    "    Returns:\n",
    "        X_train, y_train: Training data and labels.\n",
    "        X_val, y_val: Validation data and labels.\n",
    "        X_test, y_test: Testing data and labels.\n",
    "        scaler: Fitted MinMaxScaler instance for inverse scaling.\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(csv_path, parse_dates=[date_column])\n",
    "    data.sort_values(by=date_column, inplace=True)\n",
    "    \n",
    "    # Extract the 'close' column for scaling\n",
    "    close_prices = data[close_column].values.reshape(-1, 1)\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_close = scaler.fit_transform(close_prices)\n",
    "    \n",
    "    # Create sequences of time_steps\n",
    "    X, y = [], []\n",
    "    for i in range(time_steps, len(scaled_close)):\n",
    "        X.append(scaled_close[i-time_steps:i])\n",
    "        y.append(scaled_close[i])\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    # Split data into train, validation, and test sets\n",
    "    train_size = int((1 - test_size) * len(X))\n",
    "    val_size = int(val_size * train_size)\n",
    "    \n",
    "    X_train, X_temp = X[:train_size], X[train_size:]\n",
    "    y_train, y_temp = y[:train_size], y[train_size:]\n",
    "    \n",
    "    X_val, X_test = X_temp[:val_size], X_temp[val_size:]\n",
    "    y_val, y_test = y_temp[:val_size], y_temp[val_size:]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2328e744-341d-4b84-978f-4e0a5af0063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"inputs/google_stock_data.csv\"  # Path to your CSV file\n",
    "a = pd.read_csv(csv_path)\n",
    "a.head()\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f0a20ca-b77f-43ec-a3b0-c8ce448c1f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (554, 60, 1), (554, 1)\n",
      "Validation shape: (55, 60, 1), (55, 1)\n",
      "Test shape: (84, 60, 1), (84, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, scaler = preprocess_stock_data(\n",
    "    csv_path, date_column='Date', close_column='Close', time_steps=60\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3d718ef-a0b9-43d8-bfc3-ffee66a2d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_best_model(best_params, model_type):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if model_type == 'rnn':\n",
    "        for _ in range(best_params['num_layers']):\n",
    "            model.add(SimpleRNN(\n",
    "                units=best_params['units'],\n",
    "                activation='tanh',\n",
    "                return_sequences=True if _ < best_params['num_layers'] - 1 else False\n",
    "            ))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "    elif model_type == 'lstm':\n",
    "        for _ in range(best_params['num_layers']):\n",
    "            model.add(LSTM(\n",
    "                units=best_params['units'],\n",
    "                activation='tanh',\n",
    "                return_sequences=True if _ < best_params['num_layers'] - 1 else False\n",
    "            ))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "    elif model_type == 'transformer':\n",
    "        model.add(MultiHeadAttention(\n",
    "            num_heads=best_params['num_heads'],\n",
    "            key_dim=best_params['key_dim'],\n",
    "            input_shape=(None, 1)\n",
    "        ))\n",
    "        model.add(LayerNormalization())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "    elif model_type == 'neural_net':\n",
    "        for _ in range(best_params['num_layers']):\n",
    "            model.add(Dense(\n",
    "                units=best_params['units'],\n",
    "                activation='relu'\n",
    "            ))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "    elif model_type == 'ode':\n",
    "        model.add(Dense(\n",
    "            best_params['units'], activation='relu', input_dim=1\n",
    "        ))\n",
    "        for _ in range(best_params['num_layers']):\n",
    "            model.add(Dense(\n",
    "                best_params['units'], activation='relu'\n",
    "            ))\n",
    "        model.add(Dense(1))  # Approximate derivative\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate']), loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd9d800-7e51-4f5f-bf97-9e5b6fad3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Output Explanation\n",
    "Each summary() call will display:\n",
    "The layers of the model.\n",
    "The number of parameters in each layer.\n",
    "The total trainable and non-trainable parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac53c0ac-a089-43ce-a309-9ab2c0df27ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example: Print the best RNN architecture\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_rnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_best_model\u001b[49m(study_rnn\u001b[38;5;241m.\u001b[39mbest_params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrnn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest RNN Architecture:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m best_rnn_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Example: Print the best RNN architecture\n",
    "best_rnn_model = build_best_model(study_rnn.best_params, 'rnn')\n",
    "print(\"Best RNN Architecture:\")\n",
    "best_rnn_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ddddbe-2718-4e86-8850-823261b1c292",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example: Print the best LSTM architecture\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_lstm_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_best_model\u001b[49m(study_lstm\u001b[38;5;241m.\u001b[39mbest_params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest LSTM Architecture:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m best_lstm_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_best_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: Print the best LSTM architecture\n",
    "best_lstm_model = build_best_model(study_lstm.best_params, 'lstm')\n",
    "print(\"\\nBest LSTM Architecture:\")\n",
    "best_lstm_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570070f9-ad14-4c11-a043-16502f263d98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example: Print the best Transformer architecture\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_transformer_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_best_model\u001b[49m(study_transformer\u001b[38;5;241m.\u001b[39mbest_params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest Transformer Architecture:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m best_transformer_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Example: Print the best Transformer architecture\n",
    "best_transformer_model = build_best_model(study_transformer.best_params, 'transformer')\n",
    "print(\"\\nBest Transformer Architecture:\")\n",
    "best_transformer_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68892914-477e-4193-bb02-01f1705fa715",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example: Print the best Neural Network architecture\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_nn_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_best_model\u001b[49m(study_nn\u001b[38;5;241m.\u001b[39mbest_params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneural_net\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest Neural Network Architecture:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m best_nn_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Example: Print the best Neural Network architecture\n",
    "best_nn_model = build_best_model(study_nn.best_params, 'neural_net')\n",
    "print(\"\\nBest Neural Network Architecture:\")\n",
    "best_nn_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36498d90-8c1f-4f70-a068-1903445b1d17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example: Print the best ODE architecture\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_ode_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_best_model\u001b[49m(study_ode\u001b[38;5;241m.\u001b[39mbest_params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest ODE Architecture:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m best_ode_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Example: Print the best ODE architecture\n",
    "best_ode_model = build_best_model(study_ode.best_params, 'ode')\n",
    "print(\"\\nBest ODE Architecture:\")\n",
    "best_ode_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe25c69-a08b-4c24-994d-bcfe6179071f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfb338ee-b3f9-42cb-9748-793a5af464dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_data(file_path, time_steps, test_split=0.2, val_split=0.2, target_column='Close'):\n",
    "    \"\"\"\n",
    "    Prepares time series data for training, validation, and testing.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        time_steps (int): Number of time steps (look-back window) for the sequences.\n",
    "        test_split (float): Fraction of data to use for testing.\n",
    "        val_split (float): Fraction of training data to use for validation.\n",
    "        target_column (str): Column name of the target variable.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    values = data[target_column].values\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(values) - time_steps):\n",
    "        X.append(values[i:i + time_steps])\n",
    "        y.append(values[i + time_steps])\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    # Split data into train, validation, and test\n",
    "    test_size = int(len(X) * test_split)\n",
    "    val_size = int(len(X) * val_split)\n",
    "    \n",
    "    X_train, y_train = X[:-test_size - val_size], y[:-test_size - val_size]\n",
    "    X_val, y_val = X[-test_size - val_size:-test_size], y[-test_size - val_size:-test_size]\n",
    "    X_test, y_test = X[-test_size:], y[-test_size:]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c75b9-b0c1-4ab8-90d1-45266e3db047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b85e060f-40c1-4426-8e8b-1f4a9597c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, MultiHeadAttention, LayerNormalization\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_best_model(best_params, model_type, time_steps):\n",
    "    \"\"\"\n",
    "    Builds and compiles the best model based on the type and parameters.\n",
    "\n",
    "    Args:\n",
    "        best_params (dict): Best hyperparameters for the model.\n",
    "        model_type (str): Type of model ('rnn', 'lstm', 'transformer', 'neural_net', 'ode').\n",
    "        time_steps (int): Number of time steps (look-back window).\n",
    "\n",
    "    Returns:\n",
    "        Sequential: Compiled model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    if model_type == 'rnn':\n",
    "        for _ in range(best_params['num_layers']):\n",
    "            model.add(SimpleRNN(\n",
    "                units=best_params['units'],\n",
    "                activation='tanh',\n",
    "                return_sequences=True if _ < best_params['num_layers'] - 1 else False,\n",
    "                input_shape=(time_steps, 1) if _ == 0 else None\n",
    "            ))\n",
    "        model.add(Dense(1))\n",
    "    \n",
    "    elif model_type == 'lstm':\n",
    "        for _ in range(best_params['num_layers']):\n",
    "            model.add(LSTM(\n",
    "                units=best_params['units'],\n",
    "                activation='tanh',\n",
    "                return_sequences=True if _ < best_params['num_layers'] - 1 else False,\n",
    "                input_shape=(time_steps, 1) if _ == 0 else None\n",
    "            ))\n",
    "        model.add(Dense(1))\n",
    "    \n",
    "    elif model_type == 'transformer':\n",
    "        model.add(MultiHeadAttention(\n",
    "            num_heads=best_params['num_heads'],\n",
    "            key_dim=best_params['key_dim'],\n",
    "            input_shape=(None, 1)\n",
    "        ))\n",
    "        model.add(LayerNormalization())\n",
    "        model.add(Dense(1))\n",
    "    \n",
    "    elif model_type == 'neural_net':\n",
    "        model.add(Dense(\n",
    "            best_params['units'], activation='relu', input_dim=time_steps\n",
    "        ))\n",
    "        for _ in range(best_params['num_layers']):\n",
    "            model.add(Dense(\n",
    "                units=best_params['units'],\n",
    "                activation='relu'\n",
    "            ))\n",
    "        model.add(Dense(1))\n",
    "    \n",
    "    elif model_type == 'ode':\n",
    "        model.add(Dense(\n",
    "            best_params['units'], activation='relu', input_dim=time_steps\n",
    "        ))\n",
    "        for _ in range(best_params['num_layers']):\n",
    "            model.add(Dense(\n",
    "                best_params['units'], activation='relu'\n",
    "            ))\n",
    "        model.add(Dense(1))  # Approximate derivative\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate']), loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9020c-792e-4e64-a443-fd8799a0b549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
