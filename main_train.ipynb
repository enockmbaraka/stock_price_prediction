{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca4d6377-4ce1-44b5-8b3a-ce234159b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib  # For saving the scaler\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Example usage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d30e1d23-6eba-4016-8a0e-edfdca9fda77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stock_data(\n",
    "    csv_path, \n",
    "    date_column='Date', \n",
    "    close_column='Close', \n",
    "    test_size=0.2, \n",
    "    time_steps=60, \n",
    "    scaler_output_file='scaler.pkl'\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepares stock market price data for time series modeling, with training and test split.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing the data.\n",
    "        date_column (str): Name of the date column in the CSV.\n",
    "        close_column (str): Name of the closing price column in the CSV.\n",
    "        test_size (float): Proportion of the data for testing.\n",
    "        time_steps (int): Number of past time steps to use for each sample.\n",
    "        scaler_output_file (str): Path to save the fitted MinMaxScaler instance.\n",
    "\n",
    "    Returns:\n",
    "        X_train (numpy.ndarray): Training data (features).\n",
    "        y_train (numpy.ndarray): Training labels.\n",
    "        X_test (numpy.ndarray): Testing data (features).\n",
    "        y_test (numpy.ndarray): Testing labels.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        if not os.path.exists(csv_path):\n",
    "            raise FileNotFoundError(f\"CSV file not found at path: {csv_path}\")\n",
    "\n",
    "        data = pd.read_csv(csv_path, parse_dates=[date_column])\n",
    "        data.sort_values(by=date_column, inplace=True)\n",
    "\n",
    "        print(f\"CSV file successfully loaded. Columns: {data.columns}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading CSV file or parsing date column '{date_column}': {e}\")\n",
    "    \n",
    "    # Validate columns\n",
    "    if date_column not in data.columns or close_column not in data.columns:\n",
    "        raise ValueError(f\"Columns '{date_column}' or '{close_column}' not found in dataset. Available columns: {data.columns}\")\n",
    "\n",
    "    try:\n",
    "        # Extract the 'close' column for scaling\n",
    "        close_prices = data[close_column].values.reshape(-1, 1)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error accessing '{close_column}' column: {e}\")\n",
    "    \n",
    "    # Scale the data\n",
    "    try:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_close = scaler.fit_transform(close_prices)\n",
    "\n",
    "        # Save the scaler to a file\n",
    "        with open(scaler_output_file, 'wb') as f:\n",
    "            pickle.dump(scaler, f)\n",
    "        print(f\"Scaler saved to {scaler_output_file}\")\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"Error during scaling or saving scaler: {e}\")\n",
    "    \n",
    "    # Create sequences of time_steps\n",
    "    X, y = [], []\n",
    "    try:\n",
    "        for i in range(time_steps, len(scaled_close)):\n",
    "            X.append(scaled_close[i - time_steps:i])\n",
    "            y.append(scaled_close[i])\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error creating sequences of time_steps: {e}\")\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    try:\n",
    "        train_size = int((1 - test_size) * len(X))\n",
    "        X_train, X_test = X[:train_size], X[train_size:]\n",
    "        y_train, y_test = y[:train_size], y[train_size:]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error splitting data into train and test sets: {e}\")\n",
    "    \n",
    "    print(f\"Data split: {len(X_train)} training samples, {len(X_test)} testing samples\")\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4af263d4-59d7-4ae9-9228-04484ae341d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully loaded. Columns: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
      "       'daily_return', '20_day_ma', '50_day_ma'],\n",
      "      dtype='object')\n",
      "Scaler saved to outputs/google_scale.pkl\n",
      "Data split: 554 training samples, 139 testing samples\n",
      "X_train shape: (554, 60, 1), y_train shape: (554, 1)\n",
      "X_test shape: (139, 60, 1), y_test shape: (139, 1)\n"
     ]
    }
   ],
   "source": [
    "data = \"inputs/google_stock_cleaned.csv\"\n",
    "\n",
    "\n",
    "try:\n",
    "    X_train, y_train, X_test, y_test = preprocess_stock_data(\n",
    "        data, \n",
    "        date_column='Date', \n",
    "        close_column='Close', \n",
    "        test_size=0.2, \n",
    "        time_steps=60, \n",
    "        scaler_output_file='outputs/google_scale.pkl'\n",
    "    )\n",
    "\n",
    "    # Outputs\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "except ValueError as ve:\n",
    "    print(f\"ValueError: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec2defcb-9629-4bac-b23d-d261313bc8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (554, 60, 1)\n",
      "y_train shape: (554, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48cea53-4ece-4962-90a6-b3f59b8c935d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0410184-471e-4a26-8af8-5335341e5427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f201c62b-2375-4d75-ae4c-fea35106a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "class StockPricePredictor_Google:\n",
    "    def __init__(self, input_shape, learning_rate=0.0007971184552975506, num_layers=2, units=256):\n",
    "        self.input_shape = input_shape  # Should be (time_steps, features)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_layers = num_layers\n",
    "        self.units = units\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        for i in range(self.num_layers):\n",
    "            # Add RNN layers\n",
    "            return_sequences = i < (self.num_layers - 1)\n",
    "            model.add(SimpleRNN(self.units, activation='relu', return_sequences=return_sequences, input_shape=self.input_shape))\n",
    "            model.add(Dropout(0.2))  # Regularization\n",
    "\n",
    "        # Output layer for regression (single output: close value)\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
    "            loss=tf.keras.losses.MeanSquaredError(),  # Explicitly use TensorFlow's implementation\n",
    "            metrics=[tf.keras.metrics.MeanAbsoluteError()]  # Use TensorFlow's metric function\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, batch_size=16, epochs=50, validation_data=None):\n",
    "        # Validate and reshape the training data\n",
    "        X_train = self._validate_and_reshape(X_train, expected_shape=(None, *self.input_shape))\n",
    "        if validation_data:\n",
    "            X_val = self._validate_and_reshape(validation_data[0], expected_shape=(None, *self.input_shape))\n",
    "            validation_data = (X_val, validation_data[1])\n",
    "\n",
    "        # Train the model\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train, \n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs, \n",
    "            validation_data=validation_data,\n",
    "            verbose=2\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Validate and reshape the input data\n",
    "        X = self._validate_and_reshape(X, expected_shape=(None, *self.input_shape))\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def save(self, model_path):\n",
    "        # Save the model\n",
    "        self.model.save(model_path)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def load(model_path, scaler_path):\n",
    "        # Load the model\n",
    "        model = load_model(model_path)\n",
    "        print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "        # Load the scaler\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        print(f\"Scaler loaded from {scaler_path}\")\n",
    "\n",
    "        return model, scaler\n",
    "\n",
    "    def _validate_and_reshape(self, X, expected_shape):\n",
    "        \"\"\"\n",
    "        Ensures input data has the correct shape for the model.\n",
    "        \n",
    "        Args:\n",
    "            X: Input data to validate and reshape.\n",
    "            expected_shape: Tuple representing the expected shape (e.g., (None, time_steps, features)).\n",
    "        \n",
    "        Returns:\n",
    "            Reshaped data with the correct shape.\n",
    "        \"\"\"\n",
    "        if len(X.shape) == 2:  # If shape is (num_samples, time_steps)\n",
    "            reshaped = X[..., np.newaxis]  # Add a new axis for features\n",
    "            print(f\"Reshaped input from {X.shape} to {reshaped.shape}\")\n",
    "            return reshaped\n",
    "        elif len(X.shape) == len(expected_shape):  # Correct shape\n",
    "            print(f\"Input shape is valid: {X.shape}\")\n",
    "            return X\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid input shape {X.shape}. Expected shape {expected_shape}.\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "742db5ad-91a9-463a-8fe2-246b2e040d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_google = \"inputs/google_stock_cleaned.csv\"\n",
    "\n",
    "output_file = \"scaled_stock_data_close_option.pkl\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4949e12-3444-4f57-9ace-20cf5112d125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is valid: (554, 60, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input shape (0,). Expected shape (None, 60, 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 11\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      3\u001b[0m    \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Scale data\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Initialize and train the predictor\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m StockPricePredictor_Google(input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m---> 11\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Save model and scaler\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_price_rnn_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[36], line 44\u001b[0m, in \u001b[0;36mStockPricePredictor_Google.train\u001b[1;34m(self, X_train, y_train, batch_size, epochs, validation_data)\u001b[0m\n\u001b[0;32m     42\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_reshape(X_train, expected_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_shape))\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_data:\n\u001b[1;32m---> 44\u001b[0m     X_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     validation_data \u001b[38;5;241m=\u001b[39m (X_val, validation_data[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[36], line 102\u001b[0m, in \u001b[0;36mStockPricePredictor_Google._validate_and_reshape\u001b[1;34m(self, X, expected_shape)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid input shape (0,). Expected shape (None, 60, 1)."
     ]
    }
   ],
   "source": [
    "# Sample Usage\n",
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    # Scale data\n",
    "    #scaler = MinMaxScaler()\n",
    "    #y_train_scaled = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "    #y_val_scaled = scaler.transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Initialize and train the predictor\n",
    "    predictor = StockPricePredictor_Google(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    history = predictor.train(X_train, y_train, batch_size=16, epochs=20, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Save model and scaler\n",
    "    model_path = \"stock_price_rnn_model.h5\"\n",
    "    \n",
    "    predictor.save(model_path, scaler_path, scaler)\n",
    "\n",
    "    # Load model and scaler for inference\n",
    "    loaded_model, loaded_scaler = StockPricePredictor.load(model_path, scaler_path)\n",
    "    predictions = loaded_model.predict(X_val)\n",
    "    predictions_rescaled = loaded_scaler.inverse_transform(predictions)\n",
    "\n",
    "    print(\"Predictions (rescaled):\", predictions_rescaled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ebcbcd5-6693-4f35-bc16-ac8e4f6152db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is valid: (554, 60, 1)\n",
      "Input shape is valid: (139, 60, 1)\n",
      "Epoch 1/50\n",
      "35/35 - 5s - 131ms/step - loss: 0.0106 - mean_absolute_error: 0.0675 - val_loss: 0.0038 - val_mean_absolute_error: 0.0557\n",
      "Epoch 2/50\n",
      "35/35 - 1s - 42ms/step - loss: 0.0025 - mean_absolute_error: 0.0377 - val_loss: 0.0014 - val_mean_absolute_error: 0.0275\n",
      "Epoch 3/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0023 - mean_absolute_error: 0.0369 - val_loss: 0.0014 - val_mean_absolute_error: 0.0308\n",
      "Epoch 4/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0020 - mean_absolute_error: 0.0347 - val_loss: 0.0045 - val_mean_absolute_error: 0.0621\n",
      "Epoch 5/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0017 - mean_absolute_error: 0.0305 - val_loss: 9.3528e-04 - val_mean_absolute_error: 0.0244\n",
      "Epoch 6/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0024 - mean_absolute_error: 0.0369 - val_loss: 0.0012 - val_mean_absolute_error: 0.0287\n",
      "Epoch 7/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0018 - mean_absolute_error: 0.0322 - val_loss: 0.0041 - val_mean_absolute_error: 0.0589\n",
      "Epoch 8/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0016 - mean_absolute_error: 0.0304 - val_loss: 0.0036 - val_mean_absolute_error: 0.0549\n",
      "Epoch 9/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0015 - mean_absolute_error: 0.0302 - val_loss: 0.0049 - val_mean_absolute_error: 0.0651\n",
      "Epoch 10/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0021 - mean_absolute_error: 0.0349 - val_loss: 9.0532e-04 - val_mean_absolute_error: 0.0239\n",
      "Epoch 11/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0015 - mean_absolute_error: 0.0298 - val_loss: 0.0013 - val_mean_absolute_error: 0.0279\n",
      "Epoch 12/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0018 - mean_absolute_error: 0.0317 - val_loss: 0.0010 - val_mean_absolute_error: 0.0228\n",
      "Epoch 13/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0014 - mean_absolute_error: 0.0295 - val_loss: 6.6823e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 14/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0015 - mean_absolute_error: 0.0300 - val_loss: 6.9645e-04 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0016 - mean_absolute_error: 0.0300 - val_loss: 0.0035 - val_mean_absolute_error: 0.0544\n",
      "Epoch 16/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0015 - mean_absolute_error: 0.0292 - val_loss: 7.4859e-04 - val_mean_absolute_error: 0.0212\n",
      "Epoch 17/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0017 - mean_absolute_error: 0.0313 - val_loss: 0.0051 - val_mean_absolute_error: 0.0668\n",
      "Epoch 18/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0016 - mean_absolute_error: 0.0301 - val_loss: 9.6908e-04 - val_mean_absolute_error: 0.0251\n",
      "Epoch 19/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0279 - val_loss: 8.4866e-04 - val_mean_absolute_error: 0.0231\n",
      "Epoch 20/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0284 - val_loss: 8.0396e-04 - val_mean_absolute_error: 0.0222\n",
      "Epoch 21/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0014 - mean_absolute_error: 0.0288 - val_loss: 0.0018 - val_mean_absolute_error: 0.0364\n",
      "Epoch 22/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0014 - mean_absolute_error: 0.0281 - val_loss: 7.9734e-04 - val_mean_absolute_error: 0.0222\n",
      "Epoch 23/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0012 - mean_absolute_error: 0.0256 - val_loss: 7.0778e-04 - val_mean_absolute_error: 0.0203\n",
      "Epoch 24/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0013 - mean_absolute_error: 0.0278 - val_loss: 7.2859e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 25/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0015 - mean_absolute_error: 0.0279 - val_loss: 8.6495e-04 - val_mean_absolute_error: 0.0202\n",
      "Epoch 26/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0012 - mean_absolute_error: 0.0266 - val_loss: 8.6568e-04 - val_mean_absolute_error: 0.0203\n",
      "Epoch 27/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0012 - mean_absolute_error: 0.0265 - val_loss: 0.0010 - val_mean_absolute_error: 0.0256\n",
      "Epoch 28/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0015 - mean_absolute_error: 0.0298 - val_loss: 0.0016 - val_mean_absolute_error: 0.0339\n",
      "Epoch 29/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0274 - val_loss: 8.8831e-04 - val_mean_absolute_error: 0.0238\n",
      "Epoch 30/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0014 - mean_absolute_error: 0.0288 - val_loss: 6.5882e-04 - val_mean_absolute_error: 0.0188\n",
      "Epoch 31/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0014 - mean_absolute_error: 0.0289 - val_loss: 6.9105e-04 - val_mean_absolute_error: 0.0199\n",
      "Epoch 32/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0257 - val_loss: 8.3295e-04 - val_mean_absolute_error: 0.0228\n",
      "Epoch 33/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0013 - mean_absolute_error: 0.0272 - val_loss: 6.5008e-04 - val_mean_absolute_error: 0.0183\n",
      "Epoch 34/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0013 - mean_absolute_error: 0.0281 - val_loss: 0.0031 - val_mean_absolute_error: 0.0507\n",
      "Epoch 35/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0011 - mean_absolute_error: 0.0255 - val_loss: 0.0019 - val_mean_absolute_error: 0.0382\n",
      "Epoch 36/50\n",
      "35/35 - 2s - 47ms/step - loss: 0.0012 - mean_absolute_error: 0.0260 - val_loss: 8.6460e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 37/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0258 - val_loss: 9.0419e-04 - val_mean_absolute_error: 0.0240\n",
      "Epoch 38/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0012 - mean_absolute_error: 0.0261 - val_loss: 7.1171e-04 - val_mean_absolute_error: 0.0180\n",
      "Epoch 39/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0012 - mean_absolute_error: 0.0269 - val_loss: 7.3896e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 40/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0013 - mean_absolute_error: 0.0275 - val_loss: 0.0014 - val_mean_absolute_error: 0.0320\n",
      "Epoch 41/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0267 - val_loss: 9.4316e-04 - val_mean_absolute_error: 0.0247\n",
      "Epoch 42/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0011 - mean_absolute_error: 0.0263 - val_loss: 8.1478e-04 - val_mean_absolute_error: 0.0225\n",
      "Epoch 43/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0012 - mean_absolute_error: 0.0262 - val_loss: 0.0020 - val_mean_absolute_error: 0.0384\n",
      "Epoch 44/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0011 - mean_absolute_error: 0.0269 - val_loss: 0.0016 - val_mean_absolute_error: 0.0338\n",
      "Epoch 45/50\n",
      "35/35 - 1s - 42ms/step - loss: 0.0012 - mean_absolute_error: 0.0261 - val_loss: 8.3690e-04 - val_mean_absolute_error: 0.0228\n",
      "Epoch 46/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0273 - val_loss: 0.0015 - val_mean_absolute_error: 0.0327\n",
      "Epoch 47/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0011 - mean_absolute_error: 0.0255 - val_loss: 9.5234e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 48/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0010 - mean_absolute_error: 0.0242 - val_loss: 6.5088e-04 - val_mean_absolute_error: 0.0185\n",
      "Epoch 49/50\n",
      "35/35 - 2s - 45ms/step - loss: 0.0012 - mean_absolute_error: 0.0260 - val_loss: 0.0012 - val_mean_absolute_error: 0.0290\n",
      "Epoch 50/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0013 - mean_absolute_error: 0.0278 - val_loss: 7.3754e-04 - val_mean_absolute_error: 0.0181\n",
      "Input shape is valid: (139, 60, 1)\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step\n"
     ]
    }
   ],
   "source": [
    "# Example input data\n",
    "input_shape = (60, 1)  # 60 time steps, 1 feature (e.g., close price)\n",
    "predictor = StockPricePredictor_Google(input_shape=input_shape)\n",
    "\n",
    "# Training\n",
    "predictor.train(X_train, y_train, validation_data=(X_test, y_test))\n",
    "\n",
    "# Prediction\n",
    "predictions = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6cd40cc5-78b3-4e91-ac66-97a7fce763b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is valid: (554, 60, 1)\n",
      "Input shape is valid: (139, 60, 1)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\stock_price_prediction\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 - 5s - 132ms/step - loss: 0.0070 - mean_absolute_error: 0.0553 - val_loss: 0.0013 - val_mean_absolute_error: 0.0289\n",
      "Epoch 2/50\n",
      "35/35 - 1s - 42ms/step - loss: 0.0024 - mean_absolute_error: 0.0377 - val_loss: 0.0033 - val_mean_absolute_error: 0.0520\n",
      "Epoch 3/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0020 - mean_absolute_error: 0.0340 - val_loss: 0.0013 - val_mean_absolute_error: 0.0299\n",
      "Epoch 4/50\n",
      "35/35 - 2s - 44ms/step - loss: 0.0020 - mean_absolute_error: 0.0339 - val_loss: 0.0031 - val_mean_absolute_error: 0.0497\n",
      "Epoch 5/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0017 - mean_absolute_error: 0.0311 - val_loss: 0.0043 - val_mean_absolute_error: 0.0607\n",
      "Epoch 6/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0015 - mean_absolute_error: 0.0303 - val_loss: 8.6124e-04 - val_mean_absolute_error: 0.0228\n",
      "Epoch 7/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0018 - mean_absolute_error: 0.0322 - val_loss: 7.3037e-04 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/50\n",
      "35/35 - 2s - 43ms/step - loss: 0.0016 - mean_absolute_error: 0.0311 - val_loss: 0.0015 - val_mean_absolute_error: 0.0331\n",
      "Epoch 9/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0014 - mean_absolute_error: 0.0295 - val_loss: 0.0016 - val_mean_absolute_error: 0.0347\n",
      "Epoch 10/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0014 - mean_absolute_error: 0.0283 - val_loss: 0.0011 - val_mean_absolute_error: 0.0277\n",
      "Epoch 11/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0015 - mean_absolute_error: 0.0295 - val_loss: 6.7387e-04 - val_mean_absolute_error: 0.0188\n",
      "Epoch 12/50\n",
      "35/35 - 2s - 45ms/step - loss: 0.0020 - mean_absolute_error: 0.0347 - val_loss: 0.0038 - val_mean_absolute_error: 0.0563\n",
      "Epoch 13/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0016 - mean_absolute_error: 0.0298 - val_loss: 0.0019 - val_mean_absolute_error: 0.0378\n",
      "Epoch 14/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0014 - mean_absolute_error: 0.0277 - val_loss: 0.0047 - val_mean_absolute_error: 0.0642\n",
      "Epoch 15/50\n",
      "35/35 - 1s - 43ms/step - loss: 0.0013 - mean_absolute_error: 0.0278 - val_loss: 0.0014 - val_mean_absolute_error: 0.0321\n",
      "Epoch 16/50\n",
      "35/35 - 2s - 52ms/step - loss: 0.0012 - mean_absolute_error: 0.0265 - val_loss: 0.0019 - val_mean_absolute_error: 0.0375\n",
      "Epoch 17/50\n",
      "35/35 - 2s - 48ms/step - loss: 0.0013 - mean_absolute_error: 0.0273 - val_loss: 9.1240e-04 - val_mean_absolute_error: 0.0212\n",
      "Epoch 18/50\n",
      "35/35 - 2s - 57ms/step - loss: 0.0016 - mean_absolute_error: 0.0301 - val_loss: 0.0014 - val_mean_absolute_error: 0.0316\n",
      "Epoch 19/50\n",
      "35/35 - 2s - 54ms/step - loss: 0.0012 - mean_absolute_error: 0.0270 - val_loss: 7.5771e-04 - val_mean_absolute_error: 0.0213\n",
      "Epoch 20/50\n",
      "35/35 - 1s - 42ms/step - loss: 0.0012 - mean_absolute_error: 0.0262 - val_loss: 0.0012 - val_mean_absolute_error: 0.0283\n",
      "Epoch 21/50\n",
      "35/35 - 2s - 45ms/step - loss: 0.0012 - mean_absolute_error: 0.0266 - val_loss: 8.4523e-04 - val_mean_absolute_error: 0.0200\n",
      "Epoch 22/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0266 - val_loss: 0.0012 - val_mean_absolute_error: 0.0283\n",
      "Epoch 23/50\n",
      "35/35 - 2s - 45ms/step - loss: 0.0010 - mean_absolute_error: 0.0244 - val_loss: 7.6915e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 24/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0013 - mean_absolute_error: 0.0276 - val_loss: 7.5831e-04 - val_mean_absolute_error: 0.0185\n",
      "Epoch 25/50\n",
      "35/35 - 2s - 43ms/step - loss: 0.0013 - mean_absolute_error: 0.0281 - val_loss: 0.0081 - val_mean_absolute_error: 0.0863\n",
      "Epoch 26/50\n",
      "35/35 - 1s - 42ms/step - loss: 0.0014 - mean_absolute_error: 0.0287 - val_loss: 0.0031 - val_mean_absolute_error: 0.0512\n",
      "Epoch 27/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0012 - mean_absolute_error: 0.0268 - val_loss: 7.0350e-04 - val_mean_absolute_error: 0.0202\n",
      "Epoch 28/50\n",
      "35/35 - 1s - 42ms/step - loss: 0.0011 - mean_absolute_error: 0.0260 - val_loss: 0.0011 - val_mean_absolute_error: 0.0264\n",
      "Epoch 29/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0264 - val_loss: 0.0020 - val_mean_absolute_error: 0.0379\n",
      "Epoch 30/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0013 - mean_absolute_error: 0.0268 - val_loss: 0.0055 - val_mean_absolute_error: 0.0699\n",
      "Epoch 31/50\n",
      "35/35 - 2s - 45ms/step - loss: 0.0014 - mean_absolute_error: 0.0288 - val_loss: 0.0044 - val_mean_absolute_error: 0.0617\n",
      "Epoch 32/50\n",
      "35/35 - 2s - 43ms/step - loss: 0.0016 - mean_absolute_error: 0.0301 - val_loss: 6.3968e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 33/50\n",
      "35/35 - 2s - 43ms/step - loss: 0.0012 - mean_absolute_error: 0.0264 - val_loss: 0.0015 - val_mean_absolute_error: 0.0332\n",
      "Epoch 34/50\n",
      "35/35 - 2s - 44ms/step - loss: 0.0011 - mean_absolute_error: 0.0260 - val_loss: 6.6432e-04 - val_mean_absolute_error: 0.0191\n",
      "Epoch 35/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0011 - mean_absolute_error: 0.0248 - val_loss: 7.6548e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 36/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0261 - val_loss: 0.0015 - val_mean_absolute_error: 0.0307\n",
      "Epoch 37/50\n",
      "35/35 - 1s - 42ms/step - loss: 0.0013 - mean_absolute_error: 0.0280 - val_loss: 0.0018 - val_mean_absolute_error: 0.0365\n",
      "Epoch 38/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0011 - mean_absolute_error: 0.0255 - val_loss: 0.0011 - val_mean_absolute_error: 0.0245\n",
      "Epoch 39/50\n",
      "35/35 - 1s - 42ms/step - loss: 0.0011 - mean_absolute_error: 0.0253 - val_loss: 6.7958e-04 - val_mean_absolute_error: 0.0193\n",
      "Epoch 40/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0011 - mean_absolute_error: 0.0257 - val_loss: 0.0016 - val_mean_absolute_error: 0.0342\n",
      "Epoch 41/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0011 - mean_absolute_error: 0.0253 - val_loss: 0.0011 - val_mean_absolute_error: 0.0279\n",
      "Epoch 42/50\n",
      "35/35 - 2s - 43ms/step - loss: 0.0011 - mean_absolute_error: 0.0262 - val_loss: 0.0062 - val_mean_absolute_error: 0.0747\n",
      "Epoch 43/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0014 - mean_absolute_error: 0.0288 - val_loss: 0.0021 - val_mean_absolute_error: 0.0406\n",
      "Epoch 44/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0013 - mean_absolute_error: 0.0281 - val_loss: 6.7231e-04 - val_mean_absolute_error: 0.0174\n",
      "Epoch 45/50\n",
      "35/35 - 1s - 43ms/step - loss: 0.0013 - mean_absolute_error: 0.0268 - val_loss: 7.2929e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 46/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0010 - mean_absolute_error: 0.0244 - val_loss: 0.0019 - val_mean_absolute_error: 0.0374\n",
      "Epoch 47/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0011 - mean_absolute_error: 0.0253 - val_loss: 7.7982e-04 - val_mean_absolute_error: 0.0219\n",
      "Epoch 48/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0011 - mean_absolute_error: 0.0246 - val_loss: 6.8705e-04 - val_mean_absolute_error: 0.0180\n",
      "Epoch 49/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0011 - mean_absolute_error: 0.0256 - val_loss: 9.2625e-04 - val_mean_absolute_error: 0.0214\n",
      "Epoch 50/50\n",
      "35/35 - 1s - 40ms/step - loss: 9.9586e-04 - mean_absolute_error: 0.0239 - val_loss: 6.3399e-04 - val_mean_absolute_error: 0.0182\n",
      "Input shape is valid: (139, 60, 1)\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to outputs/stock_price_rnn_model.h5\n",
      "Model loaded from outputs/stock_price_rnn_model.h5\n",
      "Scaler loaded from outputs/google_scale.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\stock_price_prediction\\venv\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Load model and scaler for inference\u001b[39;00m\n\u001b[0;32m     19\u001b[0m loaded_model, loaded_scaler \u001b[38;5;241m=\u001b[39m StockPricePredictor_Google\u001b[38;5;241m.\u001b[39mload(model_path, scaler_path)\n\u001b[1;32m---> 20\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m predictions_rescaled \u001b[38;5;241m=\u001b[39m loaded_scaler\u001b[38;5;241m.\u001b[39minverse_transform(predictions)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions (rescaled):\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictions_rescaled)\n",
      "File \u001b[1;32mD:\\stock_price_prediction\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\stock_price_prediction\\venv\\Lib\\site-packages\\keras\\src\\utils\\progbar.py:119\u001b[0m, in \u001b[0;36mProgbar.update\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m    116\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     numdigits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mlog10(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    120\u001b[0m     bar \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(numdigits) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m%\u001b[39m (current, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[0;32m    121\u001b[0m     bar \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[1m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[0m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example input data\n",
    "    input_shape = (60, 1)  # 60 time steps, 1 feature (e.g., close price)\n",
    "    predictor = StockPricePredictor_Google(input_shape=input_shape)\n",
    "\n",
    "    # Training\n",
    "    predictor.train(X_train, y_train, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Prediction\n",
    "    predictions = predictor.predict(X_test)\n",
    "\n",
    "    \n",
    "    model_path = \"outputs/stock_price_rnn_model.h5\"\n",
    "    scaler_path = \"outputs/google_scale.pkl\"\n",
    "    \n",
    "    predictor.save(model_path)\n",
    "\n",
    "    # Load model and scaler for inference\n",
    "    loaded_model, loaded_scaler = StockPricePredictor_Google.load(model_path, scaler_path)\n",
    "    predictions = loaded_model.predict(X_val)\n",
    "    predictions_rescaled = loaded_scaler.inverse_transform(predictions)\n",
    "\n",
    "    print(\"Predictions (rescaled):\", predictions_rescaled)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95bb7a-e8bd-4dfd-b22e-59f4258a597d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
