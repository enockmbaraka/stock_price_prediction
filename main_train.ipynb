{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca4d6377-4ce1-44b5-8b3a-ce234159b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib  # For saving the scaler\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Example usage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d30e1d23-6eba-4016-8a0e-edfdca9fda77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stock_data(\n",
    "    csv_path, \n",
    "    date_column='Date', \n",
    "    close_column='Close', \n",
    "    test_size=0.2, \n",
    "    time_steps=60, \n",
    "    scaler_output_file='scaler.pkl'\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepares stock market price data for time series modeling, with training and test split.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing the data.\n",
    "        date_column (str): Name of the date column in the CSV.\n",
    "        close_column (str): Name of the closing price column in the CSV.\n",
    "        test_size (float): Proportion of the data for testing.\n",
    "        time_steps (int): Number of past time steps to use for each sample.\n",
    "        scaler_output_file (str): Path to save the fitted MinMaxScaler instance.\n",
    "\n",
    "    Returns:\n",
    "        X_train (numpy.ndarray): Training data (features).\n",
    "        y_train (numpy.ndarray): Training labels.\n",
    "        X_test (numpy.ndarray): Testing data (features).\n",
    "        y_test (numpy.ndarray): Testing labels.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        if not os.path.exists(csv_path):\n",
    "            raise FileNotFoundError(f\"CSV file not found at path: {csv_path}\")\n",
    "\n",
    "        data = pd.read_csv(csv_path, parse_dates=[date_column])\n",
    "        data.sort_values(by=date_column, inplace=True)\n",
    "\n",
    "        print(f\"CSV file successfully loaded. Columns: {data.columns}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading CSV file or parsing date column '{date_column}': {e}\")\n",
    "    \n",
    "    # Validate columns\n",
    "    if date_column not in data.columns or close_column not in data.columns:\n",
    "        raise ValueError(f\"Columns '{date_column}' or '{close_column}' not found in dataset. Available columns: {data.columns}\")\n",
    "\n",
    "    try:\n",
    "        # Extract the 'close' column for scaling\n",
    "        close_prices = data[close_column].values.reshape(-1, 1)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error accessing '{close_column}' column: {e}\")\n",
    "    \n",
    "    # Scale the data\n",
    "    try:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_close = scaler.fit_transform(close_prices)\n",
    "\n",
    "        # Save the scaler to a file\n",
    "        with open(scaler_output_file, 'wb') as f:\n",
    "            pickle.dump(scaler, f)\n",
    "        print(f\"Scaler saved to {scaler_output_file}\")\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"Error during scaling or saving scaler: {e}\")\n",
    "    \n",
    "    # Create sequences of time_steps\n",
    "    X, y = [], []\n",
    "    try:\n",
    "        for i in range(time_steps, len(scaled_close)):\n",
    "            X.append(scaled_close[i - time_steps:i])\n",
    "            y.append(scaled_close[i])\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error creating sequences of time_steps: {e}\")\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    try:\n",
    "        train_size = int((1 - test_size) * len(X))\n",
    "        X_train, X_test = X[:train_size], X[train_size:]\n",
    "        y_train, y_test = y[:train_size], y[train_size:]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error splitting data into train and test sets: {e}\")\n",
    "    \n",
    "    print(f\"Data split: {len(X_train)} training samples, {len(X_test)} testing samples\")\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4af263d4-59d7-4ae9-9228-04484ae341d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully loaded. Columns: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
      "       'daily_return', '20_day_ma', '50_day_ma'],\n",
      "      dtype='object')\n",
      "Scaler saved to scaler.pkl\n",
      "Data split: 554 training samples, 139 testing samples\n",
      "X_train shape: (554, 60, 1), y_train shape: (554, 1)\n",
      "X_test shape: (139, 60, 1), y_test shape: (139, 1)\n"
     ]
    }
   ],
   "source": [
    "data = \"inputs/google_stock_cleaned.csv\"\n",
    "\n",
    "\n",
    "try:\n",
    "    X_train, y_train, X_test, y_test = preprocess_stock_data(\n",
    "        data, \n",
    "        date_column='Date', \n",
    "        close_column='Close', \n",
    "        test_size=0.2, \n",
    "        time_steps=60, \n",
    "        scaler_output_file='scaler.pkl'\n",
    "    )\n",
    "\n",
    "    # Outputs\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "except ValueError as ve:\n",
    "    print(f\"ValueError: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec2defcb-9629-4bac-b23d-d261313bc8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (554, 60, 1)\n",
      "y_train shape: (554, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48cea53-4ece-4962-90a6-b3f59b8c935d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0410184-471e-4a26-8af8-5335341e5427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f201c62b-2375-4d75-ae4c-fea35106a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "class StockPricePredictor_Google:\n",
    "    def __init__(self, input_shape, learning_rate=0.0007971184552975506, num_layers=2, units=256):\n",
    "        self.input_shape = input_shape  # Should be (time_steps, features)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_layers = num_layers\n",
    "        self.units = units\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        for i in range(self.num_layers):\n",
    "            # Add RNN layers\n",
    "            return_sequences = i < (self.num_layers - 1)\n",
    "            model.add(SimpleRNN(self.units, activation='relu', return_sequences=return_sequences, input_shape=self.input_shape))\n",
    "            model.add(Dropout(0.2))  # Regularization\n",
    "\n",
    "        # Output layer for regression (single output: close value)\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
    "            loss=tf.keras.losses.MeanSquaredError(),  # Explicitly use TensorFlow's implementation\n",
    "            metrics=[tf.keras.metrics.MeanAbsoluteError()]  # Use TensorFlow's metric function\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, batch_size=16, epochs=50, validation_data=None):\n",
    "        # Validate and reshape the training data\n",
    "        X_train = self._validate_and_reshape(X_train, expected_shape=(None, *self.input_shape))\n",
    "        if validation_data:\n",
    "            X_val = self._validate_and_reshape(validation_data[0], expected_shape=(None, *self.input_shape))\n",
    "            validation_data = (X_val, validation_data[1])\n",
    "\n",
    "        # Train the model\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train, \n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs, \n",
    "            validation_data=validation_data,\n",
    "            verbose=2\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Validate and reshape the input data\n",
    "        X = self._validate_and_reshape(X, expected_shape=(None, *self.input_shape))\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def save(self, model_path, scaler_path, scaler):\n",
    "        # Save the model\n",
    "        self.model.save(model_path)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "\n",
    "        # Save the scaler\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "        print(f\"Scaler saved to {scaler_path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load(model_path, scaler_path):\n",
    "        # Load the model\n",
    "        model = load_model(model_path)\n",
    "        print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "        # Load the scaler\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        print(f\"Scaler loaded from {scaler_path}\")\n",
    "\n",
    "        return model, scaler\n",
    "\n",
    "    def _validate_and_reshape(self, X, expected_shape):\n",
    "        \"\"\"\n",
    "        Ensures input data has the correct shape for the model.\n",
    "        \n",
    "        Args:\n",
    "            X: Input data to validate and reshape.\n",
    "            expected_shape: Tuple representing the expected shape (e.g., (None, time_steps, features)).\n",
    "        \n",
    "        Returns:\n",
    "            Reshaped data with the correct shape.\n",
    "        \"\"\"\n",
    "        if len(X.shape) == 2:  # If shape is (num_samples, time_steps)\n",
    "            reshaped = X[..., np.newaxis]  # Add a new axis for features\n",
    "            print(f\"Reshaped input from {X.shape} to {reshaped.shape}\")\n",
    "            return reshaped\n",
    "        elif len(X.shape) == len(expected_shape):  # Correct shape\n",
    "            print(f\"Input shape is valid: {X.shape}\")\n",
    "            return X\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid input shape {X.shape}. Expected shape {expected_shape}.\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "742db5ad-91a9-463a-8fe2-246b2e040d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_google = \"inputs/google_stock_cleaned.csv\"\n",
    "\n",
    "output_file = \"scaled_stock_data_close_option.pkl\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4949e12-3444-4f57-9ace-20cf5112d125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is valid: (554, 60, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input shape (0,). Expected shape (None, 60, 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 11\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      3\u001b[0m    \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Scale data\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Initialize and train the predictor\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m StockPricePredictor_Google(input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m---> 11\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Save model and scaler\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_price_rnn_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[36], line 44\u001b[0m, in \u001b[0;36mStockPricePredictor_Google.train\u001b[1;34m(self, X_train, y_train, batch_size, epochs, validation_data)\u001b[0m\n\u001b[0;32m     42\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_reshape(X_train, expected_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_shape))\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_data:\n\u001b[1;32m---> 44\u001b[0m     X_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     validation_data \u001b[38;5;241m=\u001b[39m (X_val, validation_data[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[36], line 102\u001b[0m, in \u001b[0;36mStockPricePredictor_Google._validate_and_reshape\u001b[1;34m(self, X, expected_shape)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid input shape (0,). Expected shape (None, 60, 1)."
     ]
    }
   ],
   "source": [
    "# Sample Usage\n",
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    # Scale data\n",
    "    #scaler = MinMaxScaler()\n",
    "    #y_train_scaled = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "    #y_val_scaled = scaler.transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Initialize and train the predictor\n",
    "    predictor = StockPricePredictor_Google(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    history = predictor.train(X_train, y_train, batch_size=16, epochs=20, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Save model and scaler\n",
    "    model_path = \"stock_price_rnn_model.h5\"\n",
    "    \n",
    "    predictor.save(model_path, scaler_path, scaler)\n",
    "\n",
    "    # Load model and scaler for inference\n",
    "    loaded_model, loaded_scaler = StockPricePredictor.load(model_path, scaler_path)\n",
    "    predictions = loaded_model.predict(X_val)\n",
    "    predictions_rescaled = loaded_scaler.inverse_transform(predictions)\n",
    "\n",
    "    print(\"Predictions (rescaled):\", predictions_rescaled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ebcbcd5-6693-4f35-bc16-ac8e4f6152db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is valid: (554, 60, 1)\n",
      "Input shape is valid: (139, 60, 1)\n",
      "Epoch 1/50\n",
      "35/35 - 5s - 131ms/step - loss: 0.0106 - mean_absolute_error: 0.0675 - val_loss: 0.0038 - val_mean_absolute_error: 0.0557\n",
      "Epoch 2/50\n",
      "35/35 - 1s - 42ms/step - loss: 0.0025 - mean_absolute_error: 0.0377 - val_loss: 0.0014 - val_mean_absolute_error: 0.0275\n",
      "Epoch 3/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0023 - mean_absolute_error: 0.0369 - val_loss: 0.0014 - val_mean_absolute_error: 0.0308\n",
      "Epoch 4/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0020 - mean_absolute_error: 0.0347 - val_loss: 0.0045 - val_mean_absolute_error: 0.0621\n",
      "Epoch 5/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0017 - mean_absolute_error: 0.0305 - val_loss: 9.3528e-04 - val_mean_absolute_error: 0.0244\n",
      "Epoch 6/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0024 - mean_absolute_error: 0.0369 - val_loss: 0.0012 - val_mean_absolute_error: 0.0287\n",
      "Epoch 7/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0018 - mean_absolute_error: 0.0322 - val_loss: 0.0041 - val_mean_absolute_error: 0.0589\n",
      "Epoch 8/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0016 - mean_absolute_error: 0.0304 - val_loss: 0.0036 - val_mean_absolute_error: 0.0549\n",
      "Epoch 9/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0015 - mean_absolute_error: 0.0302 - val_loss: 0.0049 - val_mean_absolute_error: 0.0651\n",
      "Epoch 10/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0021 - mean_absolute_error: 0.0349 - val_loss: 9.0532e-04 - val_mean_absolute_error: 0.0239\n",
      "Epoch 11/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0015 - mean_absolute_error: 0.0298 - val_loss: 0.0013 - val_mean_absolute_error: 0.0279\n",
      "Epoch 12/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0018 - mean_absolute_error: 0.0317 - val_loss: 0.0010 - val_mean_absolute_error: 0.0228\n",
      "Epoch 13/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0014 - mean_absolute_error: 0.0295 - val_loss: 6.6823e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 14/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0015 - mean_absolute_error: 0.0300 - val_loss: 6.9645e-04 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0016 - mean_absolute_error: 0.0300 - val_loss: 0.0035 - val_mean_absolute_error: 0.0544\n",
      "Epoch 16/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0015 - mean_absolute_error: 0.0292 - val_loss: 7.4859e-04 - val_mean_absolute_error: 0.0212\n",
      "Epoch 17/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0017 - mean_absolute_error: 0.0313 - val_loss: 0.0051 - val_mean_absolute_error: 0.0668\n",
      "Epoch 18/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0016 - mean_absolute_error: 0.0301 - val_loss: 9.6908e-04 - val_mean_absolute_error: 0.0251\n",
      "Epoch 19/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0279 - val_loss: 8.4866e-04 - val_mean_absolute_error: 0.0231\n",
      "Epoch 20/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0284 - val_loss: 8.0396e-04 - val_mean_absolute_error: 0.0222\n",
      "Epoch 21/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0014 - mean_absolute_error: 0.0288 - val_loss: 0.0018 - val_mean_absolute_error: 0.0364\n",
      "Epoch 22/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0014 - mean_absolute_error: 0.0281 - val_loss: 7.9734e-04 - val_mean_absolute_error: 0.0222\n",
      "Epoch 23/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0012 - mean_absolute_error: 0.0256 - val_loss: 7.0778e-04 - val_mean_absolute_error: 0.0203\n",
      "Epoch 24/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0013 - mean_absolute_error: 0.0278 - val_loss: 7.2859e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 25/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0015 - mean_absolute_error: 0.0279 - val_loss: 8.6495e-04 - val_mean_absolute_error: 0.0202\n",
      "Epoch 26/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0012 - mean_absolute_error: 0.0266 - val_loss: 8.6568e-04 - val_mean_absolute_error: 0.0203\n",
      "Epoch 27/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0012 - mean_absolute_error: 0.0265 - val_loss: 0.0010 - val_mean_absolute_error: 0.0256\n",
      "Epoch 28/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0015 - mean_absolute_error: 0.0298 - val_loss: 0.0016 - val_mean_absolute_error: 0.0339\n",
      "Epoch 29/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0274 - val_loss: 8.8831e-04 - val_mean_absolute_error: 0.0238\n",
      "Epoch 30/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0014 - mean_absolute_error: 0.0288 - val_loss: 6.5882e-04 - val_mean_absolute_error: 0.0188\n",
      "Epoch 31/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0014 - mean_absolute_error: 0.0289 - val_loss: 6.9105e-04 - val_mean_absolute_error: 0.0199\n",
      "Epoch 32/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0257 - val_loss: 8.3295e-04 - val_mean_absolute_error: 0.0228\n",
      "Epoch 33/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0013 - mean_absolute_error: 0.0272 - val_loss: 6.5008e-04 - val_mean_absolute_error: 0.0183\n",
      "Epoch 34/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0013 - mean_absolute_error: 0.0281 - val_loss: 0.0031 - val_mean_absolute_error: 0.0507\n",
      "Epoch 35/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0011 - mean_absolute_error: 0.0255 - val_loss: 0.0019 - val_mean_absolute_error: 0.0382\n",
      "Epoch 36/50\n",
      "35/35 - 2s - 47ms/step - loss: 0.0012 - mean_absolute_error: 0.0260 - val_loss: 8.6460e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 37/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0258 - val_loss: 9.0419e-04 - val_mean_absolute_error: 0.0240\n",
      "Epoch 38/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0012 - mean_absolute_error: 0.0261 - val_loss: 7.1171e-04 - val_mean_absolute_error: 0.0180\n",
      "Epoch 39/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0012 - mean_absolute_error: 0.0269 - val_loss: 7.3896e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 40/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0013 - mean_absolute_error: 0.0275 - val_loss: 0.0014 - val_mean_absolute_error: 0.0320\n",
      "Epoch 41/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0267 - val_loss: 9.4316e-04 - val_mean_absolute_error: 0.0247\n",
      "Epoch 42/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0011 - mean_absolute_error: 0.0263 - val_loss: 8.1478e-04 - val_mean_absolute_error: 0.0225\n",
      "Epoch 43/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0012 - mean_absolute_error: 0.0262 - val_loss: 0.0020 - val_mean_absolute_error: 0.0384\n",
      "Epoch 44/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0011 - mean_absolute_error: 0.0269 - val_loss: 0.0016 - val_mean_absolute_error: 0.0338\n",
      "Epoch 45/50\n",
      "35/35 - 1s - 42ms/step - loss: 0.0012 - mean_absolute_error: 0.0261 - val_loss: 8.3690e-04 - val_mean_absolute_error: 0.0228\n",
      "Epoch 46/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0273 - val_loss: 0.0015 - val_mean_absolute_error: 0.0327\n",
      "Epoch 47/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0011 - mean_absolute_error: 0.0255 - val_loss: 9.5234e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 48/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0010 - mean_absolute_error: 0.0242 - val_loss: 6.5088e-04 - val_mean_absolute_error: 0.0185\n",
      "Epoch 49/50\n",
      "35/35 - 2s - 45ms/step - loss: 0.0012 - mean_absolute_error: 0.0260 - val_loss: 0.0012 - val_mean_absolute_error: 0.0290\n",
      "Epoch 50/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0013 - mean_absolute_error: 0.0278 - val_loss: 7.3754e-04 - val_mean_absolute_error: 0.0181\n",
      "Input shape is valid: (139, 60, 1)\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step\n"
     ]
    }
   ],
   "source": [
    "# Example input data\n",
    "input_shape = (60, 1)  # 60 time steps, 1 feature (e.g., close price)\n",
    "predictor = StockPricePredictor_Google(input_shape=input_shape)\n",
    "\n",
    "# Training\n",
    "predictor.train(X_train, y_train, validation_data=(X_test, y_test))\n",
    "\n",
    "# Prediction\n",
    "predictions = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cd40cc5-78b3-4e91-ac66-97a7fce763b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is valid: (554, 60, 1)\n",
      "Input shape is valid: (139, 60, 1)\n",
      "Epoch 1/50\n",
      "35/35 - 4s - 116ms/step - loss: 0.0115 - mean_absolute_error: 0.0670 - val_loss: 9.0537e-04 - val_mean_absolute_error: 0.0230\n",
      "Epoch 2/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0024 - mean_absolute_error: 0.0380 - val_loss: 0.0041 - val_mean_absolute_error: 0.0588\n",
      "Epoch 3/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0022 - mean_absolute_error: 0.0358 - val_loss: 0.0081 - val_mean_absolute_error: 0.0853\n",
      "Epoch 4/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0020 - mean_absolute_error: 0.0350 - val_loss: 7.5118e-04 - val_mean_absolute_error: 0.0204\n",
      "Epoch 5/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0022 - mean_absolute_error: 0.0355 - val_loss: 7.4067e-04 - val_mean_absolute_error: 0.0199\n",
      "Epoch 6/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0016 - mean_absolute_error: 0.0319 - val_loss: 0.0025 - val_mean_absolute_error: 0.0435\n",
      "Epoch 7/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0019 - mean_absolute_error: 0.0337 - val_loss: 0.0012 - val_mean_absolute_error: 0.0281\n",
      "Epoch 8/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0014 - mean_absolute_error: 0.0289 - val_loss: 0.0023 - val_mean_absolute_error: 0.0426\n",
      "Epoch 9/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0017 - mean_absolute_error: 0.0312 - val_loss: 0.0011 - val_mean_absolute_error: 0.0274\n",
      "Epoch 10/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0017 - mean_absolute_error: 0.0317 - val_loss: 8.3228e-04 - val_mean_absolute_error: 0.0227\n",
      "Epoch 11/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0015 - mean_absolute_error: 0.0301 - val_loss: 0.0016 - val_mean_absolute_error: 0.0343\n",
      "Epoch 12/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0015 - mean_absolute_error: 0.0298 - val_loss: 9.1739e-04 - val_mean_absolute_error: 0.0242\n",
      "Epoch 13/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0014 - mean_absolute_error: 0.0281 - val_loss: 8.6808e-04 - val_mean_absolute_error: 0.0204\n",
      "Epoch 14/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0273 - val_loss: 0.0020 - val_mean_absolute_error: 0.0392\n",
      "Epoch 15/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0283 - val_loss: 6.7778e-04 - val_mean_absolute_error: 0.0179\n",
      "Epoch 16/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0016 - mean_absolute_error: 0.0304 - val_loss: 0.0036 - val_mean_absolute_error: 0.0551\n",
      "Epoch 17/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0015 - mean_absolute_error: 0.0289 - val_loss: 7.4325e-04 - val_mean_absolute_error: 0.0184\n",
      "Epoch 18/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0277 - val_loss: 0.0014 - val_mean_absolute_error: 0.0317\n",
      "Epoch 19/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0014 - mean_absolute_error: 0.0276 - val_loss: 0.0048 - val_mean_absolute_error: 0.0645\n",
      "Epoch 20/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0014 - mean_absolute_error: 0.0282 - val_loss: 0.0024 - val_mean_absolute_error: 0.0437\n",
      "Epoch 21/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0015 - mean_absolute_error: 0.0292 - val_loss: 0.0048 - val_mean_absolute_error: 0.0645\n",
      "Epoch 22/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0014 - mean_absolute_error: 0.0293 - val_loss: 6.6486e-04 - val_mean_absolute_error: 0.0175\n",
      "Epoch 23/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0013 - mean_absolute_error: 0.0271 - val_loss: 8.1907e-04 - val_mean_absolute_error: 0.0224\n",
      "Epoch 24/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0012 - mean_absolute_error: 0.0265 - val_loss: 7.7374e-04 - val_mean_absolute_error: 0.0216\n",
      "Epoch 25/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0011 - mean_absolute_error: 0.0257 - val_loss: 9.4090e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 26/50\n",
      "35/35 - 1s - 42ms/step - loss: 0.0011 - mean_absolute_error: 0.0247 - val_loss: 0.0019 - val_mean_absolute_error: 0.0384\n",
      "Epoch 27/50\n",
      "35/35 - 1s - 41ms/step - loss: 0.0014 - mean_absolute_error: 0.0290 - val_loss: 6.9055e-04 - val_mean_absolute_error: 0.0178\n",
      "Epoch 28/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0015 - mean_absolute_error: 0.0296 - val_loss: 7.9135e-04 - val_mean_absolute_error: 0.0190\n",
      "Epoch 29/50\n",
      "35/35 - 2s - 43ms/step - loss: 0.0014 - mean_absolute_error: 0.0281 - val_loss: 7.7909e-04 - val_mean_absolute_error: 0.0187\n",
      "Epoch 30/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0010 - mean_absolute_error: 0.0248 - val_loss: 0.0011 - val_mean_absolute_error: 0.0275\n",
      "Epoch 31/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0011 - mean_absolute_error: 0.0262 - val_loss: 0.0017 - val_mean_absolute_error: 0.0361\n",
      "Epoch 32/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0012 - mean_absolute_error: 0.0268 - val_loss: 0.0029 - val_mean_absolute_error: 0.0492\n",
      "Epoch 33/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0283 - val_loss: 0.0022 - val_mean_absolute_error: 0.0412\n",
      "Epoch 34/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0268 - val_loss: 8.7063e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 35/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0264 - val_loss: 0.0011 - val_mean_absolute_error: 0.0272\n",
      "Epoch 36/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0013 - mean_absolute_error: 0.0273 - val_loss: 0.0011 - val_mean_absolute_error: 0.0268\n",
      "Epoch 37/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0011 - mean_absolute_error: 0.0256 - val_loss: 0.0037 - val_mean_absolute_error: 0.0557\n",
      "Epoch 38/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0266 - val_loss: 6.6327e-04 - val_mean_absolute_error: 0.0192\n",
      "Epoch 39/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0012 - mean_absolute_error: 0.0262 - val_loss: 0.0027 - val_mean_absolute_error: 0.0468\n",
      "Epoch 40/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0011 - mean_absolute_error: 0.0262 - val_loss: 9.3330e-04 - val_mean_absolute_error: 0.0215\n",
      "Epoch 41/50\n",
      "35/35 - 1s - 38ms/step - loss: 0.0013 - mean_absolute_error: 0.0275 - val_loss: 0.0010 - val_mean_absolute_error: 0.0259\n",
      "Epoch 42/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0010 - mean_absolute_error: 0.0239 - val_loss: 0.0018 - val_mean_absolute_error: 0.0362\n",
      "Epoch 43/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0012 - mean_absolute_error: 0.0265 - val_loss: 0.0011 - val_mean_absolute_error: 0.0242\n",
      "Epoch 44/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0012 - mean_absolute_error: 0.0263 - val_loss: 6.5020e-04 - val_mean_absolute_error: 0.0180\n",
      "Epoch 45/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0011 - mean_absolute_error: 0.0249 - val_loss: 0.0017 - val_mean_absolute_error: 0.0362\n",
      "Epoch 46/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0011 - mean_absolute_error: 0.0255 - val_loss: 0.0030 - val_mean_absolute_error: 0.0496\n",
      "Epoch 47/50\n",
      "35/35 - 1s - 40ms/step - loss: 0.0010 - mean_absolute_error: 0.0248 - val_loss: 0.0033 - val_mean_absolute_error: 0.0518\n",
      "Epoch 48/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0016 - mean_absolute_error: 0.0315 - val_loss: 0.0015 - val_mean_absolute_error: 0.0309\n",
      "Epoch 49/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0013 - mean_absolute_error: 0.0264 - val_loss: 0.0011 - val_mean_absolute_error: 0.0265\n",
      "Epoch 50/50\n",
      "35/35 - 1s - 39ms/step - loss: 0.0012 - mean_absolute_error: 0.0262 - val_loss: 8.2797e-04 - val_mean_absolute_error: 0.0228\n",
      "Input shape is valid: (139, 60, 1)\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000027705B9AE80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000027705B9AE80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/stock_price_rnn_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m scaler_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/google_scale.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 16\u001b[0m predictor\u001b[38;5;241m.\u001b[39msave(model_path, scaler_path, \u001b[43mscaler\u001b[49m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Load model and scaler for inference\u001b[39;00m\n\u001b[0;32m     19\u001b[0m loaded_model, loaded_scaler \u001b[38;5;241m=\u001b[39m StockPricePredictor\u001b[38;5;241m.\u001b[39mload(model_path, scaler_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example input data\n",
    "    input_shape = (60, 1)  # 60 time steps, 1 feature (e.g., close price)\n",
    "    predictor = StockPricePredictor_Google(input_shape=input_shape)\n",
    "\n",
    "    # Training\n",
    "    predictor.train(X_train, y_train, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Prediction\n",
    "    predictions = predictor.predict(X_test)\n",
    "\n",
    "    # Save model and scaler\n",
    "    model_path = \"outputs/stock_price_rnn_model.h5\"\n",
    "    scaler_path = \"outputs/google_scale.pkl\"\n",
    "    \n",
    "    predictor.save(model_path, scaler_path, scaler)\n",
    "\n",
    "    # Load model and scaler for inference\n",
    "    loaded_model, loaded_scaler = StockPricePredictor.load(model_path, scaler_path)\n",
    "    predictions = loaded_model.predict(X_val)\n",
    "    predictions_rescaled = loaded_scaler.inverse_transform(predictions)\n",
    "\n",
    "    print(\"Predictions (rescaled):\", predictions_rescaled)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95bb7a-e8bd-4dfd-b22e-59f4258a597d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
